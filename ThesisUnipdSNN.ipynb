{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ergysmedaunipd/thesis/blob/main/ThesisUnipdSNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snntorch --quiet"
      ],
      "metadata": {
        "id": "Kc3-4tqnv5AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcOCVUH7r4kE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import snntorch as snn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import snntorch.functional as SF\n",
        "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
        "\n",
        "class ADMM_NN:\n",
        "    \"\"\" Class for ADMM Neural Network. \"\"\"\n",
        "\n",
        "    def __init__(self, n_inputs, n_hiddens, n_outputs, n_batches,delta,theta,timestep):\n",
        "        \"\"\"\n",
        "        Initialize variables for NN.\n",
        "        Raises:\n",
        "            ValueError: Column input samples, for example, the input size of MNIST data should be (28x28, *) instead of (*, 28x28).\n",
        "        :param n_inputs: Number of inputs.\n",
        "        :param n_hiddens: Number of hidden units.\n",
        "        :param n_outputs: Number of outputs\n",
        "        :param n_batches: Number of data sample that you want to train\n",
        "        :param return:\n",
        "        \"\"\"\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.delta = delta\n",
        "        self.T = timestep\n",
        "        self.theta = theta\n",
        "        self.a0 = torch.zeros((n_inputs, n_batches), device=self.device)\n",
        "\n",
        "        self.w1 = torch.zeros((n_hiddens, n_inputs), device=self.device)\n",
        "        self.w2 = torch.zeros((n_hiddens, n_hiddens), device=self.device)\n",
        "        self.w3 = torch.zeros((n_outputs, n_hiddens), device=self.device)\n",
        "\n",
        "        self.z1 = torch.rand((n_hiddens, n_batches), device=self.device)\n",
        "        self.a1 = torch.rand((n_hiddens, n_batches), device=self.device)\n",
        "\n",
        "        self.z2 = torch.rand((n_hiddens, n_batches), device=self.device)\n",
        "        self.a2 = torch.rand((n_hiddens, n_batches), device=self.device)\n",
        "\n",
        "        self.z3 = torch.rand((n_outputs, n_batches), device=self.device)\n",
        "\n",
        "        self.fc1 = nn.Linear(n_inputs, n_hiddens).to(self.device)\n",
        "        self.lif1 = snn.Leaky(beta=self.delta, threshold=self.theta).to(self.device)\n",
        "\n",
        "        self.fc2 = nn.Linear(n_hiddens, n_hiddens).to(self.device)\n",
        "        self.lif2 = snn.Leaky(beta=self.delta, threshold=self.theta).to(self.device)\n",
        "\n",
        "        self.fc3 = nn.Linear(n_hiddens, n_outputs).to(self.device)\n",
        "        self.lif3 = snn.Leaky(beta=self.delta, threshold=self.theta).to(self.device)\n",
        "\n",
        "        self.lambda_larange = torch.ones((n_outputs, n_batches)).to(self.device)\n",
        "\n",
        "    def __str__(self):\n",
        "        model_str = \"ADMM SNN Model Structure:\\n\"\n",
        "        model_str += f\" - Number of timesteps: {self.T}\\n\"\n",
        "        model_str += f\" - Input dimension: {self.a0.size()}\\n\"\n",
        "        model_str += f\" - W1 : {self.w1.shape}\\n\"\n",
        "        model_str += f\" - W2 : {self.w2.shape}\\n\"\n",
        "        model_str += f\" - W3 : {self.w3.shape}\\n\"\n",
        "        model_str += f\" - z1 : {self.z1.shape}\\n\"\n",
        "        model_str += f\" - z2 : {self.z2.shape}\\n\"\n",
        "        model_str += f\" - z3 : {self.z3.shape}\\n\"\n",
        "        model_str += f\" - a0 : {self.a0.shape}\\n\"\n",
        "        model_str += f\" - a1 : {self.a1.shape}\\n\"\n",
        "        model_str += f\" - a2 : {self.a2.shape}\\n\"\n",
        "        model_str += f\" - fc1 : {self.fc1}\\n\"\n",
        "        model_str += f\" - lif1 : {self.lif1}\\n\"\n",
        "        model_str += f\" - fc2 : {self.fc2}\\n\"\n",
        "        model_str += f\" - lif2 : {self.lif2}\\n\"\n",
        "        model_str += f\" - fc3 : {self.fc3}\\n\"\n",
        "        model_str += f\" - lif3 : {self.lif3}\\n\"\n",
        "        model_str += f\" - Output dimension (Lagrange Multiplier): {self.lambda_larange.size()}\\n\"\n",
        "\n",
        "        \"\"\"Helper method to print shapes of initialized tensors\"\"\"\n",
        "        print(f\"\\nModel Initialization Details:\")\n",
        "\n",
        "\n",
        "        print(f\"lambda shape: {self.lambda_larange.shape}\")\n",
        "        return model_str\n",
        "    def _relu(self, x):\n",
        "        \"\"\"\n",
        "        Relu activation function\n",
        "        :param x: input x\n",
        "        :return: max 0 and x\n",
        "        \"\"\"\n",
        "        return F.relu(x)\n",
        "\n",
        "    def _weight_update(self, layer_output, activation_input):\n",
        "        \"\"\"\n",
        "        Consider it now the minimization of the problem with respect to W_l.\n",
        "        For each layer l, the optimal solution minimizes ||z_l - W_l a_l-1||^2. This is simply\n",
        "        a least square problem, and the solution is given by W_l = z_l p_l-1, where p_l-1\n",
        "        represents the pseudo-inverse of the rectangular activation matrix a_l-1.\n",
        "        :param layer_output: output matrix (z_l)\n",
        "        :param activation_input: activation matrix l-1  (a_l-1)\n",
        "        :return: weight matrix\n",
        "        \"\"\"\n",
        "        pinv = torch.pinverse(activation_input)\n",
        "        weight_matrix = torch.mm(layer_output.float(), pinv.float())\n",
        "        return weight_matrix\n",
        "\n",
        "    def _activation_update(self, next_weight, next_layer_output, layer_nl_output, beta, gamma):\n",
        "        \"\"\"\n",
        "        Minimization for a_l is a simple least squares problem similar to the weight update.\n",
        "        However, in this case the matrix appears in two penalty terms in the problem, and so\n",
        "        we must minimize:\n",
        "            beta ||z_l+1 - W_l+1 a_l||^2 + gamma ||a_l - h(z_l)||^2\n",
        "        :param next_weight:  weight matrix l+1 (w_l+1)\n",
        "        :param next_layer_output: output matrix l+1 (z_l+1)\n",
        "        :param layer_nl_output: activate output matrix h(z) (h(z_l))\n",
        "        :param beta: value of beta\n",
        "        :param gamma: value of gamma\n",
        "        :return: activation matrix\n",
        "        \"\"\"\n",
        "        # Calculate ReLU\n",
        "        layer_nl_output = self._relu(layer_nl_output)\n",
        "\n",
        "        # Activation inverse\n",
        "        m1 = beta * torch.mm(next_weight.t(), next_weight)\n",
        "        m2 = gamma * torch.eye(m1.shape[0], device=m1.device)\n",
        "        av = torch.inverse(m1.float() + m2.float())\n",
        "\n",
        "        # Activation formula\n",
        "        m3 = beta * torch.mm(next_weight.t(), next_layer_output)\n",
        "        m4 = gamma * layer_nl_output\n",
        "        af = m3.float() + m4.float()\n",
        "\n",
        "        # Output\n",
        "        return torch.mm(av, af)\n",
        "\n",
        "    def _argminz(self, a, w, a_in, beta, gamma):\n",
        "        \"\"\"\n",
        "        This problem is non-convex and non-quadratic (because of the non-linear term h).\n",
        "        Fortunately, because the non-linearity h works entry-wise on its argument, the entries\n",
        "        in z_l are decoupled. This is particularly easy when h is piecewise linear, as it can\n",
        "        be solved in closed form; common piecewise linear choices for h include rectified\n",
        "        linear units (ReLUs), that its used here, and non-differentiable sigmoid functions.\n",
        "        :param a: activation matrix (a_l)\n",
        "        :param w:  weight matrix (w_l)\n",
        "        :param a_in: activation matrix l-1 (a_l-1)\n",
        "        :param beta: value of beta\n",
        "        :param gamma: value of gamma\n",
        "        :return: output matrix\n",
        "        \"\"\"\n",
        "        m = torch.mm(w.float(), a_in.float())\n",
        "        sol1 = (gamma * a + beta * m) / (gamma + beta)\n",
        "        sol2 = m\n",
        "\n",
        "        z1 = torch.zeros_like(a)\n",
        "        z2 = torch.zeros_like(a)\n",
        "        z = torch.zeros_like(a)\n",
        "\n",
        "        z1[sol1 >= 0] = sol1[sol1 >= 0]\n",
        "        z2[sol2 <= 0] = sol2[sol2 <= 0]\n",
        "\n",
        "        fz_1 = gamma * (a - self._relu(z1)).pow(2) + beta * (z1 - m).pow(2)\n",
        "        fz_2 = gamma * (a - self._relu(z2)).pow(2) + beta * (z2 - m).pow(2)\n",
        "\n",
        "        index_z1 = fz_1 <= fz_2\n",
        "        index_z2 = fz_2 < fz_1\n",
        "\n",
        "        z[index_z1] = z1[index_z1]\n",
        "        z[index_z2] = z2[index_z2]\n",
        "\n",
        "        return z\n",
        "\n",
        "    def _argminlastz(self, targets, eps, w, a_in, beta):\n",
        "        \"\"\"\n",
        "        Minimization of the last output matrix, using the above function.\n",
        "        :param targets: target matrix (equal dimensions of z) (y)\n",
        "        :param eps: lagrange multiplier matrix (equal dimensions of z) (lambda)\n",
        "        :param w: weight matrix (w_l)\n",
        "        :param a_in: activation matrix l-1 (a_l-1)\n",
        "        :param beta: value of beta\n",
        "        :return: output matrix last layer\n",
        "        \"\"\"\n",
        "        m = torch.mm(w.float(), a_in.float())\n",
        "        z = (targets - eps + beta * m) / (1 + beta)\n",
        "        return z\n",
        "\n",
        "    def _lambda_update(self, zl, w, a_in, beta):\n",
        "        \"\"\"\n",
        "        Lagrange multiplier update.\n",
        "        :param zl: output matrix last layer (z_L)\n",
        "        :param w: weight matrix last layer (w_L)\n",
        "        :param a_in: activation matrix l-1 (a_L-1)\n",
        "        :param beta: value of beta\n",
        "        :return: lagrange update\n",
        "        \"\"\"\n",
        "        mpt = torch.mm(w.float(), a_in.float())\n",
        "        lambda_up = beta * (zl - mpt)\n",
        "        return lambda_up\n",
        "    def feed_forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Forward pass using ADMM weights and spiking dynamics.\n",
        "        \"\"\"\n",
        "        # Initialize membrane potentials for spiking neurons\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        spk3_rec = []\n",
        "\n",
        "        # Process inputs over timesteps\n",
        "        for step in range(self.T):\n",
        "            cur1 = torch.mm(self.w1, inputs)  # Replace fc1\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "\n",
        "            cur2 = torch.mm(self.w2, spk1)  # Replace fc2\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "\n",
        "            cur3 = torch.mm(self.w3, spk2)  # Replace fc3\n",
        "            spk3, mem3 = self.lif3(cur3, mem3)\n",
        "\n",
        "            spk3_rec.append(spk3)\n",
        "\n",
        "        # Return final membrane potential at last timestep (batch_size, num_outputs)\n",
        "        return mem3.T\n",
        "\n",
        "\n",
        "    def fit(self, inputs, labels, beta, gamma):\n",
        "        \"\"\"\n",
        "        Training ADMM Neural Network by minimizing sub-problems\n",
        "        :param inputs: input of training data samples\n",
        "        :param outputs: label of training data samples\n",
        "        :param epochs: number of epochs\n",
        "        :param beta: value of beta\n",
        "        :param gamma: value of gamma\n",
        "        :return: loss value\n",
        "        \"\"\"\n",
        "        self.a0 = inputs.to(self.device)\n",
        "\n",
        "        # Input layer\n",
        "        self.w1 = self._weight_update(self.z1, self.a0)\n",
        "        self.a1 = self._activation_update(self.w2, self.z2, self.z1, beta, gamma)\n",
        "        self.z1 = self._argminz(self.a1, self.w1, self.a0, beta, gamma)\n",
        "\n",
        "        # Hidden layer\n",
        "        self.w2 = self._weight_update(self.z2, self.a1)\n",
        "        self.a2 = self._activation_update(self.w3, self.z3, self.z2, beta, gamma)\n",
        "        self.z2 = self._argminz(self.a2, self.w2, self.a1, beta, gamma)\n",
        "\n",
        "        # Output layer\n",
        "        self.w3 = self._weight_update(self.z3, self.a2)\n",
        "        self.z3 = self._argminlastz(labels, self.lambda_larange, self.w3, self.a2, beta)\n",
        "        self.lambda_larange = self._lambda_update(self.z3, self.w3, self.a2, beta)\n",
        "\n",
        "        loss, accuracy = self.evaluate(inputs, labels)\n",
        "        return loss, accuracy\n",
        "\n",
        "    def evaluate(self, inputs, labels, isCategories=True):\n",
        "        \"\"\"\n",
        "        Calculate loss and accuracy (only classification).\n",
        "        \"\"\"\n",
        "        if labels.shape[0] != inputs.shape[0]:  # Ensure labels match input batch\n",
        "            labels = labels.T\n",
        "\n",
        "        forward = self.feed_forward(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = torch.mean((forward - labels).pow(2))\n",
        "\n",
        "        if isCategories:\n",
        "            if labels.ndim == 1:\n",
        "                # Labels are already class indices\n",
        "                accuracy = (labels == torch.argmax(forward, dim=1)).float().mean()\n",
        "            else:\n",
        "                # Labels are one-hot encoded\n",
        "                accuracy = (torch.argmax(labels, dim=1) == torch.argmax(forward, dim=1)).float().mean()\n",
        "        else:\n",
        "            accuracy = loss\n",
        "\n",
        "        return loss, accuracy\n",
        "\n",
        "\n",
        "    def warming(self, inputs, labels, epochs, beta, gamma):\n",
        "        \"\"\"\n",
        "        Warming ADMM Neural Network by minimizing sub-problems without update lambda\n",
        "        :param inputs: input of training data samples\n",
        "        :param outputs: label of training data samples\n",
        "        :param epochs: number of epochs\n",
        "        :param beta: value of beta\n",
        "        :param gamma: value of gamma\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.a0 = inputs.to(self.device)\n",
        "        for i in range(epochs):\n",
        "            print(f\"------ Warming: {i} ------\")\n",
        "            # Input layer\n",
        "            self.w1 = self._weight_update(self.z1, self.a0)\n",
        "            self.fc1.weight.data = self.w1\n",
        "            self.a1 = self._activation_update(self.w2, self.z2, self.z1, beta, gamma)\n",
        "            self.z1 = self._argminz(self.a1, self.w1, self.a0, beta, gamma)\n",
        "\n",
        "            # Hidden layer\n",
        "            self.w2 = self._weight_update(self.z2, self.a1)\n",
        "            self.fc2.weight.data = self.w2\n",
        "            self.a2 = self._activation_update(self.w3, self.z3, self.z2, beta, gamma)\n",
        "            self.z2 = self._argminz(self.a2, self.w2, self.a1, beta, gamma)\n",
        "\n",
        "            # Output layer\n",
        "            self.w3 = self._weight_update(self.z3, self.a2)\n",
        "            self.fc3.weight.data = self.w3\n",
        "            self.z3 = self._argminlastz(labels, self.lambda_larange, self.w3, self.a2, beta)\n",
        "\n",
        "    def drawcurve(self, train_, valid_, id, legend_1, legend_2):\n",
        "        acc_train = np.array(train_.cpu()).flatten() if isinstance(train_, torch.Tensor) else np.array(train_).flatten()\n",
        "        acc_test = np.array(valid_.cpu()).flatten() if isinstance(valid_, torch.Tensor) else np.array(valid_).flatten()\n",
        "\n",
        "        plt.figure(id)\n",
        "        plt.plot(acc_train, label=legend_1)\n",
        "        plt.plot(acc_test, label=legend_2)\n",
        "        plt.ylim(bottom=0)\n",
        "        plt.legend(loc='upper left')\n",
        "        plt.draw()\n",
        "        plt.pause(0.001)\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load MNIST data with proper transformations\n",
        "mnist = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Convert training data to PyTorch tensors and move to GPU\n",
        "train_data = mnist.data.view(-1, 28 * 28).T.float().to(device)  # Reshape and convert to float32\n",
        "train_labels = F.one_hot(mnist.targets, num_classes=10).T.float().to(device)  # One-hot encode labels\n",
        "\n",
        "# Load validation data\n",
        "mnist_valid = datasets.MNIST('./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# Convert validation data to PyTorch tensors and move to GPU\n",
        "valid_data = mnist_valid.data.view(-1, 28 * 28).T.float().to(device)  # Reshape and convert to float32\n",
        "valid_labels = F.one_hot(mnist_valid.targets, num_classes=10).T.float().to(device)  # One-hot encode labels\n"
      ],
      "metadata": {
        "id": "IYuF2XdhGXZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load MNIST data with proper transformations\n",
        "mnist = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Convert training data to PyTorch tensors and move to GPU\n",
        "train_data = mnist.data.view(-1, 28 * 28).T.float().to(device)  # Reshape and convert to float32\n",
        "train_labels = F.one_hot(mnist.targets, num_classes=10).T.float().to(device)  # One-hot encode labels\n",
        "\n",
        "# Load validation data\n",
        "mnist_valid = datasets.MNIST('./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# Convert validation data to PyTorch tensors and move to GPU\n",
        "valid_data = mnist_valid.data.view(-1, 28 * 28).T.float().to(device)  # Reshape and convert to float32\n",
        "valid_labels = F.one_hot(mnist_valid.targets, num_classes=10).T.float().to(device)  # One-hot encode labels\n",
        "\n",
        "n_inputs = 28*28  # MNIST image shape 28*28\n",
        "n_outputs = 10    # MNIST classes from 0-9 digits\n",
        "n_hiddens = 512   # number of neurons\n",
        "n_batches = train_data.shape[1]  # 55000 number of samples for training\n",
        "train_epochs = 100\n",
        "warm_epochs = 10\n",
        "\n",
        "# Hyperparameter grid\n",
        "beta_values = [10]\n",
        "gamma_values = [ 1]\n",
        "delta_values = [ 0.99]\n",
        "theta_values = [1]\n",
        "timestep_values = [75]\n",
        "patience = 5\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Grid search\n",
        "for timestep in timestep_values:\n",
        "    for theta in theta_values:\n",
        "        for delta in delta_values:\n",
        "            for gamma in gamma_values:\n",
        "                for beta in beta_values:\n",
        "                    print(f\"Testing: beta={beta}, gamma={gamma}, delta={delta}, theta={theta}, timestep={timestep}\")\n",
        "\n",
        "                    # Initialize model with current hyperparameters\n",
        "                    model = ADMM_NN(n_inputs, n_hiddens, n_outputs, n_batches, delta, theta, timestep)\n",
        "\n",
        "                    # Warming phase\n",
        "                    model.warming(\n",
        "                        train_data.clone().detach().to(device),\n",
        "                        train_labels.clone().detach().to(device),\n",
        "                        warm_epochs, beta, gamma\n",
        "                    )\n",
        "\n",
        "                    # Early stopping variables\n",
        "                    best_acc = 0\n",
        "\n",
        "                    patience_counter = 0\n",
        "\n",
        "                    # Training phase\n",
        "                    list_loss_train = []\n",
        "                    list_loss_valid = []\n",
        "                    list_accuracy_train = []\n",
        "                    list_accuracy_valid = []\n",
        "                    for epoch in range(train_epochs):\n",
        "                        _, accuracy_train = model.fit(\n",
        "                            train_data.clone().detach().to(device),\n",
        "                            train_labels.clone().detach().to(device),\n",
        "                            beta, gamma\n",
        "                        )\n",
        "                        _, accuracy_valid = model.evaluate(\n",
        "                            valid_data.clone().detach().to(device),\n",
        "                            valid_labels.clone().detach().to(device)\n",
        "                        )\n",
        "\n",
        "                        print(f\"------ Training Epoch: {epoch}  accuracy train: {accuracy_train:.3f}, accuracy valid: {accuracy_valid:.3f}\")\n",
        "\n",
        "                        # Append  accuracy\n",
        "                        list_accuracy_train.append(accuracy_train)\n",
        "                        list_accuracy_valid.append(accuracy_valid)\n",
        "\n",
        "                        # Early stopping logic\n",
        "                        if accuracy_valid > best_acc:\n",
        "                            best_acc = accuracy_valid\n",
        "                            patience_counter = 0  # Reset patience counter\n",
        "                        else:\n",
        "                            patience_counter += 1\n",
        "\n",
        "                        if patience_counter >= patience:\n",
        "                            print(f\"Early stopping triggered at epoch {epoch}\")\n",
        "                            break\n",
        "\n",
        "                    model.drawcurve(list_accuracy_train, list_accuracy_valid, 2, 'acc_train', 'acc_valid')\n",
        "\n",
        "                    # Evaluate on test set\n",
        "                    test_data = mnist_valid.test_data.numpy().reshape(-1, 28*28).T.astype(np.float32)\n",
        "                    test_labels = F.one_hot(mnist_valid.test_labels, num_classes=10).numpy().T.astype(np.float32)\n",
        "                    loss_test, accuracy_test = model.evaluate(\n",
        "                        torch.from_numpy(test_data).to(device),\n",
        "                        torch.from_numpy(test_labels).to(device)\n",
        "                    )\n",
        "                    print(f\"Final Test Accuracy: {accuracy_test.item():.3f}\")\n",
        "\n",
        "                    # Store results\n",
        "                    results.append({\n",
        "                        \"beta\": beta,\n",
        "                        \"gamma\": gamma,\n",
        "                        \"delta\": delta,\n",
        "                        \"theta\": theta,\n",
        "                        \"timestep\": timestep,\n",
        "                        \"loss_test\": loss_test.item(),\n",
        "                        \"accuracy_test\": accuracy_test.item()\n",
        "                    })\n",
        "\n",
        "# Display the best result\n",
        "best_result = max(results, key=lambda x: x['accuracy_test'])\n",
        "print(f\"\\nBest Hyperparameters:\")\n",
        "print(f\"Beta: {best_result['beta']}\")\n",
        "print(f\"Gamma: {best_result['gamma']}\")\n",
        "print(f\"Delta: {best_result['delta']}\")\n",
        "print(f\"Theta: {best_result['theta']}\")\n",
        "print(f\"Timestep: {best_result['timestep']}\")\n",
        "print(f\"Test Accuracy: {best_result['accuracy_test']:.3f}\")\n"
      ],
      "metadata": {
        "id": "vq49kjHswsXT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "outputId": "5c0c7306-29be-4e2b-b7ec-35d78da8f744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: beta=10, gamma=1, delta=0.99, theta=1, timestep=75\n",
            "------ Warming: 0 ------\n",
            "------ Warming: 1 ------\n",
            "------ Warming: 2 ------\n",
            "------ Warming: 3 ------\n",
            "------ Warming: 4 ------\n",
            "------ Warming: 5 ------\n",
            "------ Warming: 6 ------\n",
            "------ Warming: 7 ------\n",
            "------ Warming: 8 ------\n",
            "------ Warming: 9 ------\n",
            "------ Training Epoch: 0  accuracy train: 0.133, accuracy valid: 0.131\n",
            "------ Training Epoch: 1  accuracy train: 0.152, accuracy valid: 0.148\n",
            "------ Training Epoch: 2  accuracy train: 0.181, accuracy valid: 0.181\n",
            "------ Training Epoch: 3  accuracy train: 0.231, accuracy valid: 0.233\n",
            "------ Training Epoch: 4  accuracy train: 0.336, accuracy valid: 0.333\n",
            "------ Training Epoch: 5  accuracy train: 0.465, accuracy valid: 0.468\n",
            "------ Training Epoch: 6  accuracy train: 0.598, accuracy valid: 0.603\n",
            "------ Training Epoch: 7  accuracy train: 0.666, accuracy valid: 0.671\n",
            "------ Training Epoch: 8  accuracy train: 0.717, accuracy valid: 0.722\n",
            "------ Training Epoch: 9  accuracy train: 0.741, accuracy valid: 0.747\n",
            "------ Training Epoch: 10  accuracy train: 0.760, accuracy valid: 0.768\n",
            "------ Training Epoch: 11  accuracy train: 0.770, accuracy valid: 0.772\n",
            "------ Training Epoch: 12  accuracy train: 0.770, accuracy valid: 0.773\n",
            "------ Training Epoch: 13  accuracy train: 0.771, accuracy valid: 0.773\n",
            "------ Training Epoch: 14  accuracy train: 0.775, accuracy valid: 0.777\n",
            "------ Training Epoch: 15  accuracy train: 0.776, accuracy valid: 0.781\n",
            "------ Training Epoch: 16  accuracy train: 0.776, accuracy valid: 0.779\n",
            "------ Training Epoch: 17  accuracy train: 0.774, accuracy valid: 0.773\n",
            "------ Training Epoch: 18  accuracy train: 0.772, accuracy valid: 0.772\n",
            "------ Training Epoch: 19  accuracy train: 0.766, accuracy valid: 0.767\n",
            "------ Training Epoch: 20  accuracy train: 0.761, accuracy valid: 0.764\n",
            "Early stopping triggered at epoch 20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-83af310c0e1c>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawcurve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_accuracy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_accuracy_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'acc_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'acc_valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0;31m# Evaluate on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-dfd781bf40fe>\u001b[0m in \u001b[0;36mdrawcurve\u001b[0;34m(self, train_, valid_, id, legend_1, legend_2)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdrawcurve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0macc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import snntorch as snn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import snntorch.functional as SF\n",
        "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
        "\n",
        "class ADMM_NN:\n",
        "    \"\"\" Class for ADMM Neural Network. \"\"\"\n",
        "\n",
        "    def __init__(self, n_inputs, n_hiddens, n_outputs, n_batches,delta,theta,timesteps):\n",
        "        \"\"\"\n",
        "        Initialize variables for NN.\n",
        "        Raises:\n",
        "            ValueError: Column input samples, for example, the input size of MNIST data should be (28x28, *) instead of (*, 28x28).\n",
        "        :param n_inputs: Number of inputs.\n",
        "        :param n_hiddens: Number of hidden units.\n",
        "        :param n_outputs: Number of outputs\n",
        "        :param n_batches: Number of data sample that you want to train\n",
        "        :param return:\n",
        "        \"\"\"\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.delta = delta\n",
        "        self.T = timesteps\n",
        "\n",
        "        self.theta = theta\n",
        "        self.a0 = torch.zeros((n_inputs, n_batches), device=self.device)\n",
        "\n",
        "        self.w1 = torch.zeros((n_hiddens, n_inputs), device=self.device)\n",
        "        self.w2 = torch.zeros((n_hiddens, n_hiddens), device=self.device)\n",
        "        self.w3 = torch.zeros((n_outputs, n_hiddens), device=self.device)\n",
        "\n",
        "        self.z1 = torch.rand((n_hiddens, n_batches), device=self.device)\n",
        "        self.a1 = torch.rand((n_hiddens, n_batches), device=self.device)\n",
        "\n",
        "        self.z2 = torch.rand((n_hiddens, n_batches), device=self.device)\n",
        "        self.a2 = torch.rand((n_hiddens, n_batches), device=self.device)\n",
        "\n",
        "        self.z3 = torch.rand((n_outputs, n_batches), device=self.device)\n",
        "\n",
        "        self.fc1 = nn.Linear(n_inputs, n_hiddens).to(self.device)\n",
        "        self.lif1 = snn.Leaky(beta=self.delta, threshold=self.theta).to(self.device)\n",
        "\n",
        "        self.fc2 = nn.Linear(n_hiddens, n_hiddens).to(self.device)\n",
        "        self.lif2 = snn.Leaky(beta=self.delta, threshold=self.theta).to(self.device)\n",
        "\n",
        "        self.fc3 = nn.Linear(n_hiddens, n_outputs).to(self.device)\n",
        "        self.lif3 = snn.Leaky(beta=self.delta, threshold=self.theta).to(self.device)\n",
        "\n",
        "        self.lambda_larange = torch.ones((n_outputs, n_batches)).to(self.device)\n",
        "\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        model_str = \"ADMM SNN Model Structure:\\n\"\n",
        "\n",
        "        print(f\"lambda shape: {self.lambda_larange.shape}\")\n",
        "        return model_str\n",
        "    def _relu(self, x):\n",
        "        \"\"\"\n",
        "        Relu activation function\n",
        "        :param x: input x\n",
        "        :return: max 0 and x\n",
        "        \"\"\"\n",
        "        return F.relu(x)\n",
        "\n",
        "    def _weight_update(self, layer_output, activation_input):\n",
        "        \"\"\"\n",
        "        Update weights by minimizing ||z_l - W_l a_l-1||^2 with spike train temporal aggregation.\n",
        "        :param layer_output: Output matrix (z_l), shape [n_hiddens, n_batches].\n",
        "        :param activation_input: Spike train activations (a_l-1), shape [timesteps, n_features, n_batches].\n",
        "        :return: Weight matrix for the layer (W_l).\n",
        "        \"\"\"\n",
        "        # Aggregate activations over timesteps\n",
        "        if activation_input.dim() == 3:  # Spike train input with temporal dimension\n",
        "            integrated_activation = activation_input.sum(dim=0)  # Shape: [n_features, n_batches]\n",
        "        elif activation_input.dim() == 2:  # Already aggregated input\n",
        "            integrated_activation = activation_input  # Shape: [n_features, n_batches]\n",
        "        else:\n",
        "            raise ValueError(\"activation_input must have 2 or 3 dimensions.\")\n",
        "        # Compute pseudo-inverse\n",
        "        pinv = torch.pinverse(integrated_activation)\n",
        "\n",
        "        # Calculate updated weight matrix\n",
        "        weight_matrix = torch.mm(layer_output.float(), pinv.float())\n",
        "\n",
        "        return weight_matrix.to(self.device)\n",
        "\n",
        "\n",
        "    def _activation_update(self, next_weight, next_layer_output, layer_nl_output, beta, gamma):\n",
        "        \"\"\"\n",
        "        Minimization for a_l with spike train temporal aggregation.\n",
        "        The problem involves minimizing:\n",
        "            beta ||z_l+1 - W_l+1 a_l||^2 + gamma ||a_l - h(z_l)||^2\n",
        "        :param next_weight: Weight matrix l+1 (W_l+1).\n",
        "        :param next_layer_output: Output matrix l+1 (z_l+1), shape [n_hiddens, n_batches].\n",
        "        :param layer_nl_output: Non-linear activation matrix h(z_l), shape [timesteps, n_hiddens, n_batches].\n",
        "        :param beta: Regularization parameter for z_l+1.\n",
        "        :param gamma: Regularization parameter for a_l.\n",
        "        :return: Activation matrix a_l, shape [n_hiddens, n_batches].\n",
        "        \"\"\"\n",
        "        # Aggregate layer_nl_output over timesteps\n",
        "        integrated_activation = layer_nl_output.sum(dim=0)  # Shape: [n_hiddens, n_batches]\n",
        "\n",
        "        # Activation inverse (matrix formulation)\n",
        "        m1 = beta * torch.mm(next_weight.t(), next_weight)  # [n_hiddens, n_hiddens]\n",
        "        m2 = gamma * torch.eye(m1.shape[0], device=m1.device)  # [n_hiddens, n_hiddens]\n",
        "        # Regularize to ensure invertibility\n",
        "        epsilon = 1e-6  # Small regularization constant\n",
        "        av = torch.inverse(m1.float() + m2.float() + epsilon * torch.eye(m1.shape[0], device=m1.device))\n",
        "\n",
        "        # Activation formula\n",
        "        m3 = beta * torch.mm(next_weight.t(), next_layer_output)  # [n_hiddens, n_batches]\n",
        "        m4 = gamma * layer_nl_output  # [n_hiddens, n_batches]\n",
        "        af = m3.float() + m4.float()\n",
        "\n",
        "        # Output\n",
        "        return torch.mm(av, af).to(self.device)\n",
        "\n",
        "    def _argminz(self, a, w, a_in, beta, gamma):\n",
        "        \"\"\"\n",
        "        Minimization for z_l with temporal aggregation of spike train data.\n",
        "        :param a: Activation matrix (a_l), shape [n_hiddens, n_batches].\n",
        "        :param w: Weight matrix (w_l), shape [n_hiddens, n_features].\n",
        "        :param a_in: Input activations (spike train, a_l-1), shape [timesteps, n_features, n_batches] or [n_features, n_batches].\n",
        "        :param beta: Regularization parameter for z_l+1.\n",
        "        :param gamma: Regularization parameter for a_l.\n",
        "        :return: Output matrix z_l, shape [n_hiddens, n_batches].\n",
        "        \"\"\"\n",
        "        # Handle temporal aggregation if a_in is 3D\n",
        "        if a_in.dim() == 3:  # Spike train input with temporal dimension\n",
        "            integrated_a_in = a_in.sum(dim=0)  # Shape: [n_features, n_batches]\n",
        "        elif a_in.dim() == 2:  # Already aggregated input\n",
        "            integrated_a_in = a_in  # Shape: [n_features, n_batches]\n",
        "        else:\n",
        "            raise ValueError(\"a_in must have 2 or 3 dimensions.\")\n",
        "\n",
        "        # Compute intermediate variables\n",
        "        m = torch.mm(w.float(), integrated_a_in.float())  # Weighted input activations\n",
        "        sol1 = (gamma * a + beta * m) / (gamma + beta)  # First candidate solution\n",
        "        sol2 = m  # Second candidate solution\n",
        "\n",
        "        # Initialize z candidates\n",
        "        z1 = torch.zeros_like(a)\n",
        "        z2 = torch.zeros_like(a)\n",
        "        z = torch.zeros_like(a)\n",
        "\n",
        "        # Apply conditions to determine z1 and z2\n",
        "        z1[sol1 >= 0] = sol1[sol1 >= 0]\n",
        "        z2[sol2 <= 0] = sol2[sol2 <= 0]\n",
        "\n",
        "        # Compute objective function values for z1 and z2\n",
        "        fz_1 = gamma * (a - self._relu(z1)).pow(2) + beta * (z1 - m).pow(2)\n",
        "        fz_2 = gamma * (a - self._relu(z2)).pow(2) + beta * (z2 - m).pow(2)\n",
        "\n",
        "        # Select the better solution for each element\n",
        "        index_z1 = fz_1 <= fz_2\n",
        "        index_z2 = fz_2 < fz_1\n",
        "\n",
        "        z[index_z1] = z1[index_z1]\n",
        "        z[index_z2] = z2[index_z2]\n",
        "\n",
        "        return z\n",
        "\n",
        "    def _argminlastz(self, targets, eps, w, a_in, beta):\n",
        "        \"\"\"\n",
        "        Minimization of the last output matrix with temporal aggregation of spike train data.\n",
        "        :param targets: Target matrix (equal dimensions of z), shape [n_outputs, n_batches].\n",
        "        :param eps: Lagrange multiplier matrix (equal dimensions of z), shape [n_outputs, n_batches].\n",
        "        :param w: Weight matrix (w_L), shape [n_outputs, n_hiddens].\n",
        "        :param a_in: Input activations (spike train, a_L-1), shape [timesteps, n_hiddens, n_batches] or [n_hiddens, n_batches].\n",
        "        :param beta: Regularization parameter for the last layer.\n",
        "        :return: Output matrix z_L, shape [n_outputs, n_batches].\n",
        "        \"\"\"\n",
        "        # Handle temporal aggregation if a_in is 3D\n",
        "        if a_in.dim() == 3:  # Spike train input with temporal dimension\n",
        "            integrated_a_in = a_in.sum(dim=0)  # Shape: [n_hiddens, n_batches]\n",
        "        elif a_in.dim() == 2:  # Already aggregated input\n",
        "            integrated_a_in = a_in  # Shape: [n_hiddens, n_batches]\n",
        "        else:\n",
        "            raise ValueError(\"a_in must have 2 or 3 dimensions.\")\n",
        "\n",
        "        # Compute z_L using the aggregated input\n",
        "        m = torch.mm(w.float(), integrated_a_in.float())  # Weighted input activations\n",
        "        z = (targets - eps + beta * m) / (1 + beta)  # Closed-form solution for z\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "    def _lambda_update(self, zl, w, a_in, beta):\n",
        "        \"\"\"\n",
        "        Lagrange multiplier update with spike train temporal aggregation.\n",
        "        :param zl: Output matrix last layer (z_L), shape [n_outputs, n_batches].\n",
        "        :param w: Weight matrix last layer (w_L), shape [n_outputs, n_hiddens].\n",
        "        :param a_in: Input activations (spike train, a_L-1), shape [timesteps, n_hiddens, n_batches] or [n_hiddens, n_batches].\n",
        "        :param beta: Regularization parameter for the Lagrange multiplier update.\n",
        "        :return: Updated Lagrange multiplier matrix, shape [n_outputs, n_batches].\n",
        "        \"\"\"\n",
        "        # Handle temporal aggregation if a_in is 3D\n",
        "        if a_in.dim() == 3:  # Spike train input with temporal dimension\n",
        "            integrated_a_in = a_in.sum(dim=0)  # Shape: [n_hiddens, n_batches]\n",
        "        elif a_in.dim() == 2:  # Already aggregated input\n",
        "            integrated_a_in = a_in  # Shape: [n_hiddens, n_batches]\n",
        "        else:\n",
        "            raise ValueError(\"a_in must have 2 or 3 dimensions.\")\n",
        "\n",
        "\n",
        "        # Compute the Lagrange multiplier update\n",
        "        mpt = torch.mm(w.float(), integrated_a_in.float())  # Weighted activations\n",
        "        lambda_up = beta * (zl - mpt)  # Update rule for lambda\n",
        "\n",
        "        return lambda_up\n",
        "\n",
        "\n",
        "\n",
        "    def feed_forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Forward pass using ADMM weights and spiking dynamics with spike train inputs.\n",
        "        :param inputs: Spike train tensor, shape [timesteps, n_inputs, n_batches].\n",
        "        :return: Aggregated membrane potential or spike activity, shape [n_outputs, n_batches].\n",
        "        \"\"\"\n",
        "        inputs = inputs.to(self.device)  # Ensure inputs are on GPU\n",
        "\n",
        "        # Initialize membrane potentials for spiking neurons\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        # Initialize spike accumulation for output layer\n",
        "        spk3_rec = []  # Record spikes from the output layer\n",
        "\n",
        "        if inputs.dim() == 3:  # Spike train input with temporal dimension\n",
        "            integrated_inputs = inputs.sum(dim=0)  # Shape: [n_features, n_batches]\n",
        "        elif inputs.dim() == 2:  # Already aggregated input\n",
        "            integrated_inputs = inputs  # Shape: [n_features, n_batches]\n",
        "        else:\n",
        "            raise ValueError(\"a_in must have 2 or 3 dimensions.\")\n",
        "\n",
        "        # Process inputs over timesteps\n",
        "        for step in range(self.T):\n",
        "            cur1 = torch.mm(self.w1, integrated_inputs)  # Replace fc1\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "\n",
        "            cur2 = torch.mm(self.w2, spk1)  # Replace fc2\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "\n",
        "            cur3 = torch.mm(self.w3, spk2)  # Replace fc3\n",
        "            spk3, mem3 = self.lif3(cur3, mem3)\n",
        "\n",
        "            spk3_rec.append(spk3)\n",
        "\n",
        "\n",
        "        # Return aggregated spike counts or final membrane potential\n",
        "        return mem3.T\n",
        "\n",
        "    def fit(self, inputs, labels, beta, gamma):\n",
        "        \"\"\"\n",
        "        Training ADMM Neural Network by minimizing sub-problems.\n",
        "        :param inputs: Spike train tensor, shape [timesteps, n_inputs, n_batches].\n",
        "        :param labels: Label tensor, shape [n_outputs, n_batches].\n",
        "        :param beta: Regularization parameter for weights.\n",
        "        :param gamma: Regularization parameter for activations.\n",
        "        :return: Loss value and accuracy.\n",
        "        \"\"\"\n",
        "        # Aggregate input activations over timesteps\n",
        "        self.a0 = inputs.to(self.device)  # Shape: [n_inputs, n_batches]\n",
        "        labels = labels.to(self.device)\n",
        "\n",
        "        # Input layer\n",
        "        self.w1 = self._weight_update(self.z1, self.a0)\n",
        "        self.a1 = self._activation_update(self.w2, self.z2, self.z1, beta, gamma)\n",
        "        self.z1 = self._argminz(self.a1, self.w1, self.a0, beta, gamma)\n",
        "\n",
        "        # Hidden layer\n",
        "        self.w2 = self._weight_update(self.z2, self.a1)\n",
        "        self.a2 = self._activation_update(self.w3, self.z3, self.z2, beta, gamma)\n",
        "        self.z2 = self._argminz(self.a2, self.w2, self.a1, beta, gamma)\n",
        "\n",
        "        # Output layer\n",
        "        self.w3 = self._weight_update(self.z3, self.a2)\n",
        "        self.z3 = self._argminlastz(labels, self.lambda_larange, self.w3, self.a2, beta)\n",
        "        self.lambda_larange = self._lambda_update(self.z3, self.w3, self.a2, beta)\n",
        "\n",
        "        # Evaluate performance\n",
        "        loss, accuracy = self.evaluate(inputs, labels)\n",
        "        return loss, accuracy\n",
        "\n",
        "    def evaluate(self, inputs, labels, isCategories=True):\n",
        "        \"\"\"\n",
        "        Calculate loss and accuracy (only classification).\n",
        "        :param inputs: Spike train tensor, shape [timesteps, n_inputs, n_batches].\n",
        "        :param labels: Label tensor, shape [n_outputs, n_batches].\n",
        "        :param isCategories: Whether the task is classification.\n",
        "        :return: Loss value and accuracy.\n",
        "        \"\"\"\n",
        "        inputs = inputs.to(self.device)\n",
        "        labels = labels.to(self.device)\n",
        "\n",
        "        # Forward pass\n",
        "        forward = self.feed_forward(inputs)  # Aggregated output shape: [n_batches, n_outputs]\n",
        "\n",
        "        # Transpose forward to match labels\n",
        "        forward = forward.T  # Now shape is [n_outputs, n_batches]\n",
        "\n",
        "\n",
        "        # Compute loss\n",
        "        loss = torch.mean((forward - labels).pow(2))\n",
        "\n",
        "        # Compute accuracy (if applicable)\n",
        "        if isCategories:\n",
        "            if labels.ndim == 1:  # Labels as class indices\n",
        "                accuracy = (labels == torch.argmax(forward, dim=0)).float().mean()\n",
        "            else:  # Labels as one-hot encoded\n",
        "                accuracy = (torch.argmax(labels, dim=0) == torch.argmax(forward, dim=0)).float().mean()\n",
        "        else:\n",
        "            accuracy = loss\n",
        "\n",
        "        return loss, accuracy\n",
        "\n",
        "\n",
        "\n",
        "    def warming(self, inputs, labels, epochs, beta, gamma):\n",
        "        \"\"\"\n",
        "        Warming ADMM Neural Network by minimizing sub-problems without updating lambda.\n",
        "        :param inputs: Spike train tensor, shape [timesteps, n_inputs, n_batches].\n",
        "        :param labels: Label tensor, shape [n_outputs, n_batches].\n",
        "        :param epochs: Number of warming epochs.\n",
        "        :param beta: Regularization parameter for weights.\n",
        "        :param gamma: Regularization parameter for activations.\n",
        "        \"\"\"\n",
        "        self.a0 = inputs.sum(dim=0).to(self.device)  # Shape: [n_inputs, n_batches]\n",
        "        labels = labels.to(self.device)\n",
        "\n",
        "        for i in range(epochs):\n",
        "            # Input layer\n",
        "            self.w1 = self._weight_update(self.z1, self.a0)\n",
        "            self.fc1.weight.data = self.w1\n",
        "            self.a1 = self._activation_update(self.w2, self.z2, self.z1, beta, gamma)\n",
        "            self.z1 = self._argminz(self.a1, self.w1, self.a0, beta, gamma)\n",
        "\n",
        "            # Hidden layer\n",
        "            self.w2 = self._weight_update(self.z2, self.a1)\n",
        "            self.fc2.weight.data = self.w2\n",
        "            self.a2 = self._activation_update(self.w3, self.z3, self.z2, beta, gamma)\n",
        "            self.z2 = self._argminz(self.a2, self.w2, self.a1, beta, gamma)\n",
        "\n",
        "            # Output layer\n",
        "            self.w3 = self._weight_update(self.z3, self.a2)\n",
        "            self.fc3.weight.data = self.w3\n",
        "            self.z3 = self._argminlastz(labels, self.lambda_larange, self.w3, self.a2, beta)\n",
        "\n",
        "\n",
        "    def drawcurve(self, train_, valid_, id, legend_1, legend_2):\n",
        "        acc_train = np.array(train_).flatten()\n",
        "        acc_test = np.array(valid_).flatten()\n",
        "        plt.figure(id)\n",
        "        plt.plot(acc_train, label=legend_1)\n",
        "        plt.plot(acc_test, label=legend_2)\n",
        "        plt.ylim(bottom=0)\n",
        "        plt.legend(loc='upper left')\n",
        "        plt.draw()\n",
        "        plt.pause(0.001)\n",
        "        return 0"
      ],
      "metadata": {
        "id": "u1EdCWg6KCXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rate_coding(data, timesteps):\n",
        "    \"\"\"\n",
        "    Converts static input data to spike trains using rate coding.\n",
        "    :param data: Input tensor of shape (num_samples, num_features)\n",
        "    :param timesteps: Number of timesteps for spiking simulation\n",
        "    :return: Spike train tensor of shape (timesteps, num_samples, num_features)\n",
        "    \"\"\"\n",
        "    spike_trains = torch.rand((timesteps, data.size(0), data.size(1))).to(data.device) < data.unsqueeze(0)\n",
        "    return spike_trains.float()\n"
      ],
      "metadata": {
        "id": "x62OR-ppGmCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load MNIST data with proper transformations\n",
        "mnist = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Convert training data to PyTorch tensors and move to GPU\n",
        "train_data = mnist.data.view(-1, 28 * 28).T.float().to(device)  # Reshape and convert to float32\n",
        "train_labels = F.one_hot(mnist.targets, num_classes=10).T.float().to(device)  # One-hot encode labels\n",
        "\n",
        "# Load validation data\n",
        "mnist_valid = datasets.MNIST('./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# Convert validation data to PyTorch tensors and move to GPU\n",
        "valid_data = mnist_valid.data.view(-1, 28 * 28).T.float().to(device)  # Reshape and convert to float32\n",
        "valid_labels = F.one_hot(mnist_valid.targets, num_classes=10).T.float().to(device)  # One-hot encode labels\n",
        "\n",
        "\n",
        "# Convert the entire dataset into spike trains\n",
        "timestep = 20  # Number of timesteps\n",
        "spike_train_data = rate_coding(train_data, timestep)\n",
        "spike_valid_data = rate_coding(valid_data, timestep)"
      ],
      "metadata": {
        "id": "zgBHO85YJypB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "n_inputs = timestep* 28 * 28  # MNIST image shape 28x28\n",
        "n_outputs = 10      # MNIST classes from 0-9 digits\n",
        "n_hiddens = 512     # Number of neurons in the hidden layer\n",
        "n_batches = train_data.shape[1]  # Number of samples for training\n",
        "train_epochs = 100\n",
        "warm_epochs = 10\n",
        "beta = 12\n",
        "gamma = 0.5\n",
        "delta = 0.99\n",
        "theta = 0.7\n",
        "\n",
        "# Initialize the model\n",
        "model = ADMM_NN(n_inputs, n_hiddens, n_outputs, n_batches, delta, theta, timestep)\n",
        "\n",
        "model.warming(spike_train_data, train_labels, warm_epochs, beta, gamma)\n",
        "\n",
        "# Lists to store metrics\n",
        "list_loss_train = []\n",
        "list_loss_valid = []\n",
        "list_accuracy_train = []\n",
        "list_accuracy_valid = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(train_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{train_epochs}\")\n",
        "\n",
        "    # Training phase\n",
        "    epoch_accuracy_train = 0.0\n",
        "    _, accuracy_train = model.fit(spike_train_data, train_labels, beta, gamma)\n",
        "    epoch_accuracy_train += accuracy_train.item()\n",
        "\n",
        "    # Validation phase\n",
        "    epoch_accuracy_valid = 0.0\n",
        "    loss_valid, accuracy_valid = model.evaluate(spike_valid_data, valid_labels)\n",
        "    epoch_accuracy_valid += accuracy_valid.item()\n",
        "\n",
        "\n",
        "    # Print epoch metrics\n",
        "    print(f\"Training Accuracy: {epoch_accuracy_train:.4f}\")\n",
        "    print(f\" Validation Accuracy: {epoch_accuracy_valid:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyzjwkwwJ1Lb",
        "outputId": "abe1b8ab-d8ff-423a-ba36-7b3c72440eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "Training Accuracy: 0.1795\n",
            " Validation Accuracy: 0.1810\n",
            "Epoch 2/100\n",
            "Training Accuracy: 0.1781\n",
            " Validation Accuracy: 0.1811\n",
            "Epoch 3/100\n",
            "Training Accuracy: 0.1793\n",
            " Validation Accuracy: 0.1723\n",
            "Epoch 4/100\n",
            "Training Accuracy: 0.1798\n",
            " Validation Accuracy: 0.1707\n",
            "Epoch 5/100\n",
            "Training Accuracy: 0.1803\n",
            " Validation Accuracy: 0.1786\n",
            "Epoch 6/100\n",
            "Training Accuracy: 0.1807\n",
            " Validation Accuracy: 0.1801\n",
            "Epoch 7/100\n",
            "Training Accuracy: 0.1873\n",
            " Validation Accuracy: 0.1814\n",
            "Epoch 8/100\n",
            "Training Accuracy: 0.1919\n",
            " Validation Accuracy: 0.1864\n",
            "Epoch 9/100\n",
            "Training Accuracy: 0.1959\n",
            " Validation Accuracy: 0.1956\n",
            "Epoch 10/100\n",
            "Training Accuracy: 0.2040\n",
            " Validation Accuracy: 0.1981\n",
            "Epoch 11/100\n",
            "Training Accuracy: 0.2117\n",
            " Validation Accuracy: 0.2042\n",
            "Epoch 12/100\n",
            "Training Accuracy: 0.2189\n",
            " Validation Accuracy: 0.2134\n",
            "Epoch 13/100\n",
            "Training Accuracy: 0.2302\n",
            " Validation Accuracy: 0.2236\n",
            "Epoch 14/100\n",
            "Training Accuracy: 0.2410\n",
            " Validation Accuracy: 0.2361\n",
            "Epoch 15/100\n",
            "Training Accuracy: 0.2524\n",
            " Validation Accuracy: 0.2432\n",
            "Epoch 16/100\n",
            "Training Accuracy: 0.2637\n",
            " Validation Accuracy: 0.2537\n",
            "Epoch 17/100\n",
            "Training Accuracy: 0.2761\n",
            " Validation Accuracy: 0.2699\n",
            "Epoch 18/100\n",
            "Training Accuracy: 0.2916\n",
            " Validation Accuracy: 0.2833\n",
            "Epoch 19/100\n",
            "Training Accuracy: 0.3059\n",
            " Validation Accuracy: 0.2968\n",
            "Epoch 20/100\n",
            "Training Accuracy: 0.3205\n",
            " Validation Accuracy: 0.3170\n",
            "Epoch 21/100\n",
            "Training Accuracy: 0.3353\n",
            " Validation Accuracy: 0.3277\n",
            "Epoch 22/100\n",
            "Training Accuracy: 0.3529\n",
            " Validation Accuracy: 0.3442\n",
            "Epoch 23/100\n",
            "Training Accuracy: 0.3694\n",
            " Validation Accuracy: 0.3676\n",
            "Epoch 24/100\n",
            "Training Accuracy: 0.3849\n",
            " Validation Accuracy: 0.3805\n",
            "Epoch 25/100\n",
            "Training Accuracy: 0.4018\n",
            " Validation Accuracy: 0.3962\n",
            "Epoch 26/100\n",
            "Training Accuracy: 0.4190\n",
            " Validation Accuracy: 0.4124\n",
            "Epoch 27/100\n",
            "Training Accuracy: 0.4347\n",
            " Validation Accuracy: 0.4341\n",
            "Epoch 28/100\n",
            "Training Accuracy: 0.4504\n",
            " Validation Accuracy: 0.4479\n",
            "Epoch 29/100\n",
            "Training Accuracy: 0.4658\n",
            " Validation Accuracy: 0.4582\n",
            "Epoch 30/100\n",
            "Training Accuracy: 0.4821\n",
            " Validation Accuracy: 0.4763\n",
            "Epoch 31/100\n",
            "Training Accuracy: 0.4954\n",
            " Validation Accuracy: 0.4884\n",
            "Epoch 32/100\n",
            "Training Accuracy: 0.5102\n",
            " Validation Accuracy: 0.5007\n",
            "Epoch 33/100\n",
            "Training Accuracy: 0.5091\n",
            " Validation Accuracy: 0.4997\n",
            "Epoch 34/100\n",
            "Training Accuracy: 0.5202\n",
            " Validation Accuracy: 0.5107\n",
            "Epoch 35/100\n",
            "Training Accuracy: 0.5304\n",
            " Validation Accuracy: 0.5235\n",
            "Epoch 36/100\n",
            "Training Accuracy: 0.5440\n",
            " Validation Accuracy: 0.5368\n",
            "Epoch 37/100\n",
            "Training Accuracy: 0.5559\n",
            " Validation Accuracy: 0.5498\n",
            "Epoch 38/100\n",
            "Training Accuracy: 0.5645\n",
            " Validation Accuracy: 0.5603\n",
            "Epoch 39/100\n",
            "Training Accuracy: 0.5748\n",
            " Validation Accuracy: 0.5720\n",
            "Epoch 40/100\n",
            "Training Accuracy: 0.5860\n",
            " Validation Accuracy: 0.5809\n",
            "Epoch 41/100\n",
            "Training Accuracy: 0.5927\n",
            " Validation Accuracy: 0.5849\n",
            "Epoch 42/100\n",
            "Training Accuracy: 0.5997\n",
            " Validation Accuracy: 0.5943\n",
            "Epoch 43/100\n",
            "Training Accuracy: 0.6086\n",
            " Validation Accuracy: 0.6026\n",
            "Epoch 44/100\n",
            "Training Accuracy: 0.6142\n",
            " Validation Accuracy: 0.6085\n",
            "Epoch 45/100\n",
            "Training Accuracy: 0.6221\n",
            " Validation Accuracy: 0.6144\n",
            "Epoch 46/100\n",
            "Training Accuracy: 0.6287\n",
            " Validation Accuracy: 0.6236\n",
            "Epoch 47/100\n",
            "Training Accuracy: 0.6349\n",
            " Validation Accuracy: 0.6268\n",
            "Epoch 48/100\n",
            "Training Accuracy: 0.6418\n",
            " Validation Accuracy: 0.6304\n",
            "Epoch 49/100\n",
            "Training Accuracy: 0.6468\n",
            " Validation Accuracy: 0.6373\n",
            "Epoch 50/100\n",
            "Training Accuracy: 0.6507\n",
            " Validation Accuracy: 0.6446\n",
            "Epoch 51/100\n",
            "Training Accuracy: 0.6552\n",
            " Validation Accuracy: 0.6474\n",
            "Epoch 52/100\n",
            "Training Accuracy: 0.6592\n",
            " Validation Accuracy: 0.6490\n",
            "Epoch 53/100\n",
            "Training Accuracy: 0.6621\n",
            " Validation Accuracy: 0.6560\n",
            "Epoch 54/100\n",
            "Training Accuracy: 0.6674\n",
            " Validation Accuracy: 0.6605\n",
            "Epoch 55/100\n",
            "Training Accuracy: 0.6366\n",
            " Validation Accuracy: 0.6267\n",
            "Epoch 56/100\n",
            "Training Accuracy: 0.6405\n",
            " Validation Accuracy: 0.6309\n",
            "Epoch 57/100\n",
            "Training Accuracy: 0.6462\n",
            " Validation Accuracy: 0.6376\n",
            "Epoch 58/100\n",
            "Training Accuracy: 0.6481\n",
            " Validation Accuracy: 0.6413\n",
            "Epoch 59/100\n",
            "Training Accuracy: 0.6546\n",
            " Validation Accuracy: 0.6487\n",
            "Epoch 60/100\n",
            "Training Accuracy: 0.6571\n",
            " Validation Accuracy: 0.6481\n",
            "Epoch 61/100\n",
            "Training Accuracy: 0.6608\n",
            " Validation Accuracy: 0.6549\n",
            "Epoch 62/100\n",
            "Training Accuracy: 0.6643\n",
            " Validation Accuracy: 0.6535\n",
            "Epoch 63/100\n",
            "Training Accuracy: 0.6684\n",
            " Validation Accuracy: 0.6590\n",
            "Epoch 64/100\n",
            "Training Accuracy: 0.6707\n",
            " Validation Accuracy: 0.6640\n",
            "Epoch 65/100\n",
            "Training Accuracy: 0.6737\n",
            " Validation Accuracy: 0.6646\n",
            "Epoch 66/100\n",
            "Training Accuracy: 0.6768\n",
            " Validation Accuracy: 0.6678\n",
            "Epoch 67/100\n",
            "Training Accuracy: 0.6781\n",
            " Validation Accuracy: 0.6691\n",
            "Epoch 68/100\n",
            "Training Accuracy: 0.6814\n",
            " Validation Accuracy: 0.6739\n",
            "Epoch 69/100\n",
            "Training Accuracy: 0.6824\n",
            " Validation Accuracy: 0.6789\n",
            "Epoch 70/100\n",
            "Training Accuracy: 0.6865\n",
            " Validation Accuracy: 0.6790\n",
            "Epoch 71/100\n",
            "Training Accuracy: 0.6874\n",
            " Validation Accuracy: 0.6826\n",
            "Epoch 72/100\n",
            "Training Accuracy: 0.6908\n",
            " Validation Accuracy: 0.6825\n",
            "Epoch 73/100\n",
            "Training Accuracy: 0.6915\n",
            " Validation Accuracy: 0.6825\n",
            "Epoch 74/100\n",
            "Training Accuracy: 0.6925\n",
            " Validation Accuracy: 0.6841\n",
            "Epoch 75/100\n",
            "Training Accuracy: 0.6951\n",
            " Validation Accuracy: 0.6873\n",
            "Epoch 76/100\n",
            "Training Accuracy: 0.6969\n",
            " Validation Accuracy: 0.6890\n",
            "Epoch 77/100\n",
            "Training Accuracy: 0.6982\n",
            " Validation Accuracy: 0.6929\n",
            "Epoch 78/100\n",
            "Training Accuracy: 0.6997\n",
            " Validation Accuracy: 0.6918\n",
            "Epoch 79/100\n",
            "Training Accuracy: 0.6997\n",
            " Validation Accuracy: 0.6968\n",
            "Epoch 80/100\n",
            "Training Accuracy: 0.7012\n",
            " Validation Accuracy: 0.6995\n",
            "Epoch 81/100\n",
            "Training Accuracy: 0.7025\n",
            " Validation Accuracy: 0.6995\n",
            "Epoch 82/100\n",
            "Training Accuracy: 0.7028\n",
            " Validation Accuracy: 0.6974\n",
            "Epoch 83/100\n",
            "Training Accuracy: 0.7046\n",
            " Validation Accuracy: 0.7006\n",
            "Epoch 84/100\n",
            "Training Accuracy: 0.7039\n",
            " Validation Accuracy: 0.6993\n",
            "Epoch 85/100\n",
            "Training Accuracy: 0.7059\n",
            " Validation Accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "Training Accuracy: 0.7052\n",
            " Validation Accuracy: 0.6972\n",
            "Epoch 87/100\n",
            "Training Accuracy: 0.7073\n",
            " Validation Accuracy: 0.6998\n",
            "Epoch 88/100\n",
            "Training Accuracy: 0.7083\n",
            " Validation Accuracy: 0.6987\n",
            "Epoch 89/100\n",
            "Training Accuracy: 0.7102\n",
            " Validation Accuracy: 0.7054\n",
            "Epoch 90/100\n",
            "Training Accuracy: 0.7097\n",
            " Validation Accuracy: 0.7038\n",
            "Epoch 91/100\n",
            "Training Accuracy: 0.7096\n",
            " Validation Accuracy: 0.7058\n",
            "Epoch 92/100\n",
            "Training Accuracy: 0.7096\n",
            " Validation Accuracy: 0.7038\n",
            "Epoch 93/100\n",
            "Training Accuracy: 0.7112\n",
            " Validation Accuracy: 0.7023\n",
            "Epoch 94/100\n",
            "Training Accuracy: 0.7112\n",
            " Validation Accuracy: 0.7074\n",
            "Epoch 95/100\n",
            "Training Accuracy: 0.7123\n",
            " Validation Accuracy: 0.7102\n",
            "Epoch 96/100\n",
            "Training Accuracy: 0.7124\n",
            " Validation Accuracy: 0.7039\n",
            "Epoch 97/100\n",
            "Training Accuracy: 0.7139\n",
            " Validation Accuracy: 0.7066\n",
            "Epoch 98/100\n",
            "Training Accuracy: 0.7138\n",
            " Validation Accuracy: 0.7106\n",
            "Epoch 99/100\n",
            "Training Accuracy: 0.7132\n",
            " Validation Accuracy: 0.7096\n",
            "Epoch 100/100\n",
            "Training Accuracy: 0.7141\n",
            " Validation Accuracy: 0.7112\n"
          ]
        }
      ]
    }
  ]
}