{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDOJDXwdBURiavlUa18Srz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ddb5eaedc5c146ec81721bf79bfb31bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69432ab51d5b45f187091d7d780b65b5",
              "IPY_MODEL_7c004040f79d4206993e13b6f5810ce8",
              "IPY_MODEL_a8918ff6f2584f2192b438f43d48b8e6"
            ],
            "layout": "IPY_MODEL_e99143355988488aa697b4328908a30a"
          }
        },
        "69432ab51d5b45f187091d7d780b65b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbec077acfcc4eb9bc4075ba0ff97a88",
            "placeholder": "​",
            "style": "IPY_MODEL_50ce3dfee9be4f9880bbd23d0c4237df",
            "value": ""
          }
        },
        "7c004040f79d4206993e13b6f5810ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ffb4850841a4613b1f6f1d1c6bc02c8",
            "max": 1011893601,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4aa07d7edc454920b42c0bcb58b6bfb9",
            "value": 1011893601
          }
        },
        "a8918ff6f2584f2192b438f43d48b8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a39dd0c13d4403990ff49cad3ab7332",
            "placeholder": "​",
            "style": "IPY_MODEL_82cc0d7900694c3b822a0c211c048380",
            "value": " 1011894272/? [00:31&lt;00:00, 35138251.59it/s]"
          }
        },
        "e99143355988488aa697b4328908a30a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbec077acfcc4eb9bc4075ba0ff97a88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50ce3dfee9be4f9880bbd23d0c4237df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ffb4850841a4613b1f6f1d1c6bc02c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aa07d7edc454920b42c0bcb58b6bfb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a39dd0c13d4403990ff49cad3ab7332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82cc0d7900694c3b822a0c211c048380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48b496dbb46b43778bc7815fb4b440d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67155332301d46f48619f8b24a57ff05",
              "IPY_MODEL_83966ad7494f42a7966880fcfc946395",
              "IPY_MODEL_bf975dcd726a4bfc86846b4b6c20a509"
            ],
            "layout": "IPY_MODEL_474733dd34d940f098ad001ce84fd974"
          }
        },
        "67155332301d46f48619f8b24a57ff05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ea7cac6939e413493a5675384251184",
            "placeholder": "​",
            "style": "IPY_MODEL_423b77af118f44b9a8c576ac994766da",
            "value": ""
          }
        },
        "83966ad7494f42a7966880fcfc946395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66f89292fd8c46eb83fa03df508bdffe",
            "max": 169674850,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c1820eda1464cd9b28e1db0a344baec",
            "value": 169674850
          }
        },
        "bf975dcd726a4bfc86846b4b6c20a509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03ca749668e249b190afeccd0b271879",
            "placeholder": "​",
            "style": "IPY_MODEL_1790f671834f4b17870cfb923d952fa4",
            "value": " 169675776/? [00:05&lt;00:00, 33972041.52it/s]"
          }
        },
        "474733dd34d940f098ad001ce84fd974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ea7cac6939e413493a5675384251184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423b77af118f44b9a8c576ac994766da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66f89292fd8c46eb83fa03df508bdffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c1820eda1464cd9b28e1db0a344baec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03ca749668e249b190afeccd0b271879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1790f671834f4b17870cfb923d952fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ergysmedaunipd/thesis/blob/main/ThesisUnipdSNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tonic\n",
        "!pip install snntorch\n",
        "!pip install psutil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc3-4tqnv5AS",
        "outputId": "5f1b5790-ac65-4e5a-f15e-b82783ff38c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tonic\n",
            "  Downloading tonic-1.5.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from tonic) (1.26.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from tonic) (3.12.1)\n",
            "Collecting importRosbag>=1.0.4 (from tonic)\n",
            "  Downloading importRosbag-1.0.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tonic) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tonic) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from tonic) (4.12.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from tonic) (0.10.2.post1)\n",
            "Collecting pbr (from tonic)\n",
            "  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting expelliarmus (from tonic)\n",
            "  Downloading expelliarmus-1.1.12-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from importRosbag>=1.0.4->tonic) (75.1.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa->tonic) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->tonic) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->tonic) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->tonic) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->tonic) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa->tonic) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->tonic) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic) (2024.8.30)\n",
            "Downloading tonic-1.5.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importRosbag-1.0.4-py3-none-any.whl (28 kB)\n",
            "Downloading expelliarmus-1.1.12-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pbr, importRosbag, expelliarmus, tonic\n",
            "Successfully installed expelliarmus-1.1.12 importRosbag-1.0.4 pbr-6.1.0 tonic-1.5.0\n",
            "Collecting snntorch\n",
            "  Downloading snntorch-0.9.1-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.5.0+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from snntorch) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.26.4)\n",
            "Collecting nir (from snntorch)\n",
            "  Downloading nir-1.0.4-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting nirtorch (from snntorch)\n",
            "  Downloading nirtorch-1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.1.0->snntorch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (2.8.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from nir->snntorch) (3.12.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->snntorch) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->snntorch) (3.0.2)\n",
            "Downloading snntorch-0.9.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nir-1.0.4-py3-none-any.whl (18 kB)\n",
            "Downloading nirtorch-1.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: nir, nirtorch, snntorch\n",
            "Successfully installed nir-1.0.4 nirtorch-1.0 snntorch-0.9.1\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zcOCVUH7r4kE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "import time\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "\n",
        "\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class ADMM_SNN:\n",
        "    \"\"\" Class for ADMM Neural Network. \"\"\"\n",
        "\n",
        "    def __init__(self, n_samples: int, n_timesteps: int, input_dim: int, hidden_dims: List[int], n_outputs: int, rho: float, delta: float, theta: float):\n",
        "        \"\"\"\n",
        "        Initialize the ADMM-SNN model.\n",
        "\n",
        "        Parameters:\n",
        "        n_samples (int): Number of samples in the batch.\n",
        "        n_timesteps (int): Number of timesteps.\n",
        "        input_dim (int): Dimension of the input features.\n",
        "        hidden_dims (List[int]): List of hidden layer dimensions.\n",
        "        n_outputs (int): Number of output classes.\n",
        "        rho (float): ADMM penalty parameter.\n",
        "        delta (float): Decay factor for the intermediate variables (z).\n",
        "        theta (float): Activation threshold for the spiking neurons.\n",
        "        \"\"\"\n",
        "        # Define the device to run the model on (GPU if available)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Store model parameters\n",
        "        self.n_samples = n_samples\n",
        "        self.n_timesteps = n_timesteps\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dims = hidden_dims\n",
        "        self.n_outputs = n_outputs\n",
        "\n",
        "\n",
        "        # Loss function for training\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Hyperparameters for ADMM-SNN\n",
        "        self.rho = rho             # ADMM penalty parameter\n",
        "        self.delta = delta         # Decay factor for z updates\n",
        "        self.theta = theta         # Activation threshold for spiking neurons\n",
        "\n",
        "        # Model architecture specifications\n",
        "        self.L = len(hidden_dims)+1  # Number of hidden layers\n",
        "        self.T = n_timesteps       # Number of timesteps in each forward pass\n",
        "\n",
        "        # Initialize initial activations (a0) as a tensor with zero values\n",
        "        self.a_minus_one = torch.rand((n_timesteps, n_samples, input_dim)).to(self.device)\n",
        "\n",
        "        # Initialize weights (W) for each layer in hidden_dims\n",
        "        prev_dim = input_dim\n",
        "        self.W = nn.ParameterList()\n",
        "        for hidden_dim in hidden_dims:\n",
        "            self.W.append(nn.Parameter(\n",
        "                torch.randn(hidden_dim, prev_dim).to(self.device)   # Changed from zeros to small random\n",
        "            ))\n",
        "            prev_dim = hidden_dim\n",
        "\n",
        "        # Output layer weights\n",
        "        self.W.append(nn.Parameter(\n",
        "            torch.randn(n_outputs, hidden_dims[-1]).to(self.device)  # Changed from zeros to small random\n",
        "        ))\n",
        "\n",
        "        # Initialize intermediate variables (z) for each layer and timestep\n",
        "        self.z = []\n",
        "        for hidden_dim in hidden_dims:\n",
        "            z_layer = torch.rand((n_timesteps, n_samples, hidden_dim)).to(self.device)  # small random values\n",
        "            self.z.append(z_layer)\n",
        "        self.z.append(torch.rand((n_timesteps, n_samples, n_outputs)).to(self.device))\n",
        "\n",
        "\n",
        "\n",
        "        # Initialize activations (a) for each layer and timestep\n",
        "        self.a = []\n",
        "        for hidden_dim in hidden_dims:\n",
        "            a_layer = torch.rand((n_timesteps, n_samples, hidden_dim)).to(self.device)   # small random values\n",
        "            self.a.append(a_layer)\n",
        "        self.a.append(torch.rand((n_timesteps, n_samples, n_outputs)).to(self.device))\n",
        "\n",
        "        # Initialize Lagrange multipliers (lambda) for the output layer\n",
        "        self.lambda_lagrange = torch.ones((n_samples, n_outputs)).to(self.device)\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        model_str = \"ADMM SNN Model Structure:\\n\"\n",
        "        model_str += f\" - rho: {self.rho}, delta: {self.delta}, theta: {self.theta}\\n\"\n",
        "        model_str += f\" - Number of timesteps: {self.T}\\n\"\n",
        "        model_str += f\" - Input dimension: {self.a_minus_one.size()}\\n\"\n",
        "        model_str += f\" - Hidden layers: {[w.shape for w in self.W]}\\n\"\n",
        "        model_str += f\" - Output dimension (Lagrange Multiplier): {self.lambda_lagrange.size()}\\n\"\n",
        "        model_str += f\" - self.L : {self.L }\\n\"\n",
        "        model_str += f\" - self.T : {self.T }\\n\"\n",
        "\n",
        "        \"\"\"Helper method to print shapes of initialized tensors\"\"\"\n",
        "        print(f\"\\nModel Initialization Details:\")\n",
        "        print(f\"Device: {self.device}\")\n",
        "        print(f\"Previous activation shape: {self.a_minus_one.shape}\")\n",
        "\n",
        "        for i, w in enumerate(self.W):\n",
        "            print(f\"Weight layer {i} shape: {w.shape}\")\n",
        "\n",
        "        for i, z_layer in enumerate(self.z):\n",
        "            print(f\"z[{i}] shape: {z_layer.shape}\")\n",
        "\n",
        "        for i, a_layer in enumerate(self.a):\n",
        "            print(f\"a[{i}] shape: {a_layer.shape}\")\n",
        "\n",
        "        for i, lambda_layer in enumerate(self.lambda_lagrange):\n",
        "            print(f\"lambda[{i}] shape: {lambda_layer.shape}\")\n",
        "            return model_str\n",
        "\n",
        "    def _heaviside(self, z):\n",
        "        \"\"\"\n",
        "        Implement the Heaviside function to calculate activations based on a threshold.\n",
        "        This function returns 1 where z meets or exceeds the threshold and 0 otherwise.\n",
        "\n",
        "        Parameters:\n",
        "        z (torch.Tensor): The input tensor representing the intermediate variable z at layer l and time t.\n",
        "\n",
        "        Returns:\n",
        "        torch.Tensor: A tensor of the same shape as z with values 0 or 1, based on whether each element\n",
        "                      in z is above or below the threshold self.theta.\n",
        "        \"\"\"\n",
        "        # Apply the Heaviside step function:\n",
        "        # Convert continuous values in z to binary values (0 or 1) based on self.theta\n",
        "        # - Returns 1 where z >= theta (neuron spikes).\n",
        "        # - Returns 0 where z < theta (neuron does not spike).\n",
        "        return (z >= self.theta).float()\n",
        "\n",
        "\n",
        "    # ============ W_{l} update functions ============\n",
        "    def _weight_update(self, l):\n",
        "        \"\"\"\n",
        "        Update weights based on Equation (4) for layers 1 to L-1.\n",
        "        Parameters:\n",
        "        - l: layer index\n",
        "        Returns: W_l with shape [features_out, features_in]\n",
        "        \"\"\"\n",
        "        alpha = self.rho / 2\n",
        "        z_l = self.z[l]\n",
        "        a_l = self.a[l]\n",
        "        a_l_minus_1 = self.a[l-1] if l > 0 else self.a_minus_one\n",
        "\n",
        "        n_timesteps, batch_size, n_features = z_l.shape\n",
        "        _, _, n_prev_features = a_l_minus_1.shape\n",
        "\n",
        "        numerator = torch.zeros((n_features, n_prev_features), device=self.device)\n",
        "        denominator = torch.zeros((n_prev_features, n_prev_features), device=self.device)\n",
        "\n",
        "        for t in range(n_timesteps):\n",
        "            if t == 0:\n",
        "                x_l_t = z_l[0]\n",
        "            else:\n",
        "                x_l_t = z_l[t] - self.delta * z_l[t-1] + self.theta * a_l[t-1]\n",
        "\n",
        "            numerator += alpha * torch.einsum('bf,bp->fp', x_l_t, a_l_minus_1[t])\n",
        "            denominator += alpha * torch.einsum('bp,bq->pq', a_l_minus_1[t], a_l_minus_1[t])\n",
        "\n",
        "        denominator += torch.eye(denominator.shape[0], device=self.device) * 1e-6\n",
        "        return numerator @ torch.inverse(denominator)\n",
        "\n",
        "    def _weight_update_L(self, y):\n",
        "        \"\"\"\n",
        "        Update weights for the final layer L based on Equation (6).\n",
        "        Parameters:\n",
        "        - y: target values [batch, n_outputs]\n",
        "        Returns: W_L with shape [features_out, features_in]\n",
        "        \"\"\"\n",
        "        alpha = self.rho / 2\n",
        "        z_L = self.z[self.L-1]\n",
        "        a_L_minus_1 = self.a[self.L-2]\n",
        "\n",
        "        n_timesteps, batch_size, n_features = z_L.shape\n",
        "        _, _, n_prev_features = a_L_minus_1.shape\n",
        "\n",
        "        # Calculate lambda term\n",
        "        lambda_term = -0.5 * torch.einsum('bf,bp->fp', self.lambda_lagrange, a_L_minus_1[-1])\n",
        "\n",
        "        # Calculate sum term for numerator\n",
        "        sum_term = torch.zeros((n_features, n_prev_features), device=self.device)\n",
        "        for t in range(n_timesteps):\n",
        "            if t == 0:\n",
        "                x_L_t = z_L[0]\n",
        "            else:\n",
        "                x_L_t = z_L[t] - self.delta * z_L[t-1]\n",
        "\n",
        "            sum_term += alpha * torch.einsum('bf,bp->fp', x_L_t, a_L_minus_1[t])\n",
        "\n",
        "        # Calculate denominator\n",
        "        denominator = torch.zeros((n_prev_features, n_prev_features), device=self.device)\n",
        "        for t in range(n_timesteps):\n",
        "            denominator += alpha * torch.einsum('bp,bq->pq', a_L_minus_1[t], a_L_minus_1[t])\n",
        "\n",
        "        denominator += torch.eye(denominator.shape[0], device=self.device) * 1e-6\n",
        "        return (lambda_term + sum_term) @ torch.inverse(denominator)\n",
        "\n",
        "\n",
        "    # ============ a_{l,t} update functions ============\n",
        "    # Activation update for l=1,...,L-2, t=1,...,T-1 (Equation 8)\n",
        "    def _calculate_u_w_v(self, l, t):\n",
        "        \"\"\"\n",
        "        Calculate helper vectors u_l, v_l, w_l\n",
        "        \"\"\"\n",
        "\n",
        "        z_l = self.z[l]\n",
        "        a_l = self.a[l]\n",
        "        a_l_minus_1 = self.a[l-1] if l > 0 else self.a_minus_one\n",
        "\n",
        "        # Calculate u_l[t]\n",
        "        if t == 0:\n",
        "            u_l_t = z_l[0]\n",
        "        else:\n",
        "            u_l_t = z_l[t] - self.delta * z_l[t-1]\n",
        "\n",
        "        # Calculate v_l[t]\n",
        "        if t == 0:\n",
        "            v_l_t = u_l_t\n",
        "        else:\n",
        "            v_l_t = u_l_t + self.theta * a_l[t-1]\n",
        "\n",
        "        # Calculate w_l[t]\n",
        "        projected_a = torch.matmul(a_l_minus_1[t], self.W[l].t())\n",
        "        w_l_t = u_l_t - projected_a\n",
        "\n",
        "        return u_l_t, w_l_t, v_l_t\n",
        "\n",
        "    def _activation_update(self, l, t):\n",
        "        \"\"\"\n",
        "        Update activations based on equation (8)\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = self.rho / 2\n",
        "        beta = alpha\n",
        "\n",
        "        # Get dimensions\n",
        "        batch_size = self.z[l][t].shape[0]  # 256\n",
        "        n_features = self.z[l][t].shape[1]  # 128 for layer 0\n",
        "        W_next = self.W[l+1]  # [64, 128] for layer 0->1\n",
        "\n",
        "        # Matrix terms\n",
        "        I = torch.eye(n_features, device=self.device)\n",
        "        term1 = (self.theta ** 2) * alpha * I\n",
        "        term2 = alpha * W_next.t() @ W_next  # [128, 64] @ [64, 128] -> [128, 128]\n",
        "        term3 = beta * I\n",
        "\n",
        "        matrix_to_invert = term1 + term2 + term3\n",
        "\n",
        "        # Calculate RHS terms\n",
        "        _, w_next, _ = self._calculate_u_w_v(l, t+1)\n",
        "        rhs_term1 = -self.theta * alpha * w_next  # [256, 128]\n",
        "\n",
        "        _, _, v_next = self._calculate_u_w_v(l+1, t)  # v_next shape: [256, 64]\n",
        "        # Fix: multiply in correct order\n",
        "        rhs_term2 = alpha * torch.matmul(v_next, W_next)  # [256, 64] @ [64, 128] -> [256, 128]\n",
        "\n",
        "        heaviside_term = self._heaviside(self.z[l][t])  # [256, 128]\n",
        "        rhs_term3 = beta * heaviside_term\n",
        "\n",
        "        # Combine RHS terms\n",
        "        rhs = rhs_term1 + rhs_term2 + rhs_term3\n",
        "\n",
        "        # Solve the system\n",
        "        updated_a = torch.linalg.solve(matrix_to_invert, rhs.t()).t()\n",
        "\n",
        "        return updated_a\n",
        "\n",
        "    # Activation update for l=L-1, t=1,...,T-1 (Equation 10)\n",
        "    def _activation_update_T(self, l):\n",
        "        \"\"\"\n",
        "        Update activations for l=1,...,L-2 at t=T based on equation (9):\n",
        "        a_l,T = (α_l+1,t*W_{l+1}^T*W_{l+1} + β_l,t*I)^{-1} *\n",
        "                (α_l+1,t*W_{l+1}^T*v_{l+1,t} + β_l,t*h_l(z_l,t))\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = self.rho / 2\n",
        "        beta = alpha\n",
        "\n",
        "        # Get dimensions\n",
        "        batch_size = self.z[l][self.T-1].shape[0]  # 256\n",
        "        n_features = self.z[l][self.T-1].shape[1]  # current layer features\n",
        "        W_next = self.W[l+1]\n",
        "\n",
        "        # Calculate matrix to invert: α_l+1,t*W_{l+1}^T*W_{l+1} + β_l,t*I\n",
        "        term1 = alpha * W_next.t() @ W_next\n",
        "        term2 = beta * torch.eye(n_features, device=self.device)\n",
        "        matrix_to_invert = term1 + term2\n",
        "\n",
        "        # Calculate v_{l+1,t} for the first RHS term\n",
        "        _, _, v_next = self._calculate_u_w_v(l+1, self.T-1)\n",
        "        # Fix: multiply in correct order\n",
        "        rhs_term1 = alpha * torch.matmul(v_next, W_next)  # [256, 64] @ [64, 128] -> [256, 128]\n",
        "\n",
        "        # Calculate h_l(z_l,t) for second RHS term\n",
        "        heaviside_term = self._heaviside(self.z[l][self.T-1])  # [256, 128]\n",
        "        rhs_term2 = beta * heaviside_term\n",
        "\n",
        "        # Combine RHS terms\n",
        "        rhs = rhs_term1 + rhs_term2\n",
        "\n",
        "        # Solve the system\n",
        "        updated_a = torch.linalg.solve(matrix_to_invert, rhs.t()).t()\n",
        "\n",
        "        return updated_a\n",
        "\n",
        "    def _activation_update_Lminus1(self, t):\n",
        "        \"\"\"\n",
        "        Update activations for l=L-1 based on equation (11):\n",
        "        a_L-1,t = (α_L,t*W_L^T*W_L + β_L-1,t*I)^{-1} *\n",
        "                  (W_L^T(α_L,t*u_L,t - λ/2*1(t=T)) + β_L-1,t*h_L-1(z_L-1,t - θ))\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = self.rho / 2\n",
        "        beta = alpha\n",
        "        l = self.L - 2  # L-1 in zero-based indexing\n",
        "\n",
        "        # Get dimensions\n",
        "        batch_size = self.z[l][t].shape[0]\n",
        "        n_features = self.z[l][t].shape[1]\n",
        "        W_L = self.W[self.L-1]\n",
        "\n",
        "        # Calculate matrix to invert: α_L,t*W_L^T*W_L + β_L-1,t*I\n",
        "        term1 = alpha * W_L.t() @ W_L\n",
        "        term2 = beta * torch.eye(n_features, device=self.device)\n",
        "        matrix_to_invert = term1 + term2\n",
        "\n",
        "        # Calculate u_L,t\n",
        "        u_L, _, _ = self._calculate_u_w_v(self.L-1, t)\n",
        "\n",
        "        # Calculate first part of RHS: W_L^T(α_L,t*u_L,t)\n",
        "        # Transpose u_L to match W_L dimensions\n",
        "        rhs_term1 = alpha * (W_L.t() @ u_L.t()).t()  # Resulting in shape [batch_size, n_features]\n",
        "\n",
        "        # Add lambda term if t=T-1\n",
        "        if t == self.T-1:\n",
        "            rhs_term1 -= (W_L.t() @ (self.lambda_lagrange / 2)).t()\n",
        "\n",
        "        # Calculate h_L-1(z_L-1,t - θ)\n",
        "        heaviside_term = self._heaviside(self.z[l][t] - self.theta)\n",
        "        rhs_term2 = beta * heaviside_term\n",
        "\n",
        "        # Combine RHS terms\n",
        "        rhs = rhs_term1 + rhs_term2\n",
        "\n",
        "        # Solve the system\n",
        "        updated_a = torch.linalg.solve(matrix_to_invert, rhs.t()).t()\n",
        "\n",
        "        return updated_a\n",
        "\n",
        "    def _activation_update_Lminus1_T(self):\n",
        "        \"\"\"\n",
        "        Update activations for l=L-1 at t=T based on equation (11) with t=T:\n",
        "        a_L-1,T = (α_L,T*W_L^T*W_L + β_L-1,T*I)^{-1} *\n",
        "                  (W_L^T(α_L,T*u_L,T - λ/2) + β_L-1,T*h_L-1(z_L-1,T - θ))\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = self.rho / 2\n",
        "        beta = alpha\n",
        "        l = self.L - 2  # L-1 in zero-based indexing\n",
        "        t = self.T - 1  # T in zero-based indexing\n",
        "\n",
        "        # Get dimensions\n",
        "        batch_size = self.z[l][t].shape[0]\n",
        "        n_features = self.z[l][t].shape[1]\n",
        "        W_L = self.W[self.L-1]\n",
        "\n",
        "        # Calculate matrix to invert: α_L,T*W_L^T*W_L + β_L-1,T*I\n",
        "        term1 = alpha * W_L.t() @ W_L\n",
        "        term2 = beta * torch.eye(n_features, device=self.device)\n",
        "        matrix_to_invert = term1 + term2\n",
        "\n",
        "        # Calculate u_L,T for final timestep\n",
        "        u_L, _, _ = self._calculate_u_w_v(self.L-1, t)\n",
        "\n",
        "        # Calculate RHS: W_L^T(α_L,T*u_L,T - λ/2)\n",
        "        # Ensure correct multiplication order and transpose where necessary\n",
        "        rhs_term1 = (W_L.t() @ (alpha * u_L.t() - (self.lambda_lagrange / 2).t())).t()  # Adjusted for shape compatibility\n",
        "\n",
        "\n",
        "        # Calculate h_L-1(z_L-1,T - θ)\n",
        "        heaviside_term = self._heaviside(self.z[l][t] - self.theta)\n",
        "        rhs_term2 = beta * heaviside_term\n",
        "\n",
        "        # Combine RHS terms\n",
        "        rhs = rhs_term1 + rhs_term2\n",
        "\n",
        "        # Solve the system\n",
        "        updated_a = torch.linalg.solve(matrix_to_invert, rhs.t()).t()\n",
        "\n",
        "        return updated_a\n",
        "\n",
        "     # ============ z_{l,t} update functions ============\n",
        "    def _calculate_p_s_q_r(self, l, t):\n",
        "        \"\"\"\n",
        "        Calculate helper vectors defined in paper:\n",
        "        p_l = W_l[a_l-1,1, ..., a_l-1,T]\n",
        "        s_l = p_l + δ[0, z_l,1, ..., z_l,T-1]\n",
        "        q_l = s_l - θ[0, a_l,1, ..., a_l,T-1]\n",
        "        r_l = -p_l + z_l\n",
        "        \"\"\"\n",
        "\n",
        "        # Get previous layer activations and current layer data\n",
        "        a_l_minus_1 = self.a[l-1] if l > 0 else self.a_minus_one\n",
        "\n",
        "        # Calculate p_l: project previous layer activations through weights\n",
        "        p_l = torch.matmul(a_l_minus_1[t], self.W[l].t())  # [batch, features]\n",
        "\n",
        "        # Calculate s_l: add decayed previous z values\n",
        "        if t == 0:\n",
        "            s_l = p_l\n",
        "        else:\n",
        "            s_l = p_l + self.delta * self.z[l][t-1]\n",
        "\n",
        "        # Calculate q_l: subtract theta-weighted activations\n",
        "        if t == 0:\n",
        "            q_l = s_l\n",
        "        else:\n",
        "            q_l = s_l - self.theta * self.a[l][t-1]\n",
        "\n",
        "        # Calculate r_l: negative p_l plus current z\n",
        "        r_l = -p_l + self.z[l][t]\n",
        "\n",
        "        return p_l, s_l, q_l, r_l\n",
        "\n",
        "    def _z_update(self, l, t):\n",
        "        \"\"\"\n",
        "        Update z_{l,t} for l=1,...,L-1 and t=1,...,T-1\n",
        "        z_{l,t} = (α_l,t*q_l,t + α_l,t+1*δ(r_l,t+1 + θa_l,t)*1(t<T)) / (α_l,t + δ²α_l,t+1*1(t<T))\n",
        "        \"\"\"\n",
        "        alpha = self.rho / 2\n",
        "\n",
        "        # Calculate helper vectors\n",
        "        _, _, q_l, r_l = self._calculate_p_s_q_r(l, t)\n",
        "\n",
        "        # Calculate initial z update (before check_entries)\n",
        "        numerator = alpha * q_l\n",
        "\n",
        "        if t < self.T - 1:\n",
        "            _, _, _, r_next = self._calculate_p_s_q_r(l, t+1)\n",
        "            second_term = alpha * self.delta * (r_next + self.theta * self.a[l][t])\n",
        "            numerator = numerator + second_term\n",
        "\n",
        "        denominator = alpha\n",
        "        if t < self.T - 1:\n",
        "            denominator = denominator + (self.delta ** 2) * alpha\n",
        "\n",
        "        # Initial z update\n",
        "        z_update = numerator / denominator\n",
        "\n",
        "        # Apply check_entries\n",
        "        return self.check_entries(z_update, lambda z: alpha * torch.norm(z - q_l)**2)\n",
        "\n",
        "    def _z_update_T(self, l):\n",
        "        \"\"\"\n",
        "        Update z_{l,T} for l=1,...,L-1\n",
        "        z_{l,T} = q_{l,T}\n",
        "        \"\"\"\n",
        "        # Calculate helper vectors for final timestep\n",
        "        _, _, q_l, _ = self._calculate_p_s_q_r(l, self.T-1)\n",
        "\n",
        "        # For final timestep, z_{l,T} = q_{l,T}\n",
        "        z_update = q_l\n",
        "\n",
        "        # Apply check_entries\n",
        "        return self.check_entries(z_update, lambda z: self.rho/2 * torch.norm(z - q_l)**2)\n",
        "\n",
        "    def _z_update_L(self, t, y):\n",
        "        \"\"\"\n",
        "        Update z_{L,t} for t=1,...,T-1 based on equation (16):\n",
        "        z_{L,t} = (α_L,t*s_L,t + α_L,t+1*δr_L,t+1*1(t<T) + (y-λ/2)*1(t=T)) /\n",
        "                  (α_L,t + δ²α_L,t+1*1(t<T) + 1(t=T))\n",
        "        \"\"\"\n",
        "        alpha = self.rho / 2\n",
        "        l = self.L - 1  # Last layer index\n",
        "\n",
        "        # Calculate helper vectors\n",
        "        _, s_l, _, r_l = self._calculate_p_s_q_r(l, t)\n",
        "\n",
        "        # First term: α_L,t*s_L,t\n",
        "        numerator = alpha * s_l\n",
        "\n",
        "        # Handle t < T case\n",
        "        if t < self.T - 1:\n",
        "            # Calculate r_{L,t+1} for next timestep\n",
        "            _, _, _, r_next = self._calculate_p_s_q_r(l, t+1)\n",
        "            # Add second term: α_L,t+1*δr_L,t+1\n",
        "            numerator = numerator + alpha * self.delta * r_next\n",
        "            denominator = alpha + (self.delta**2 * alpha)\n",
        "        else:\n",
        "            # Final timestep: add (y-λ/2) term\n",
        "            numerator = numerator + (y - self.lambda_lagrange/2)\n",
        "            denominator = alpha + 1.0\n",
        "\n",
        "        # Calculate update\n",
        "        z_update = numerator / denominator\n",
        "\n",
        "        # Apply check_entries with appropriate cost function\n",
        "        def cost_fn(z):\n",
        "            cost = alpha * torch.norm(z - s_l)**2\n",
        "            if t < self.T - 1:\n",
        "                # Add cost term for t < T case\n",
        "                _, _, _, r_next = self._calculate_p_s_q_r(l, t+1)\n",
        "                cost += alpha * torch.norm(r_next - self.delta * z)**2\n",
        "            else:\n",
        "                # Add cost term for t = T case\n",
        "                cost += torch.norm(z - y)**2 + torch.sum(self.lambda_lagrange * z)\n",
        "            return cost\n",
        "\n",
        "        return self.check_entries(z_update, cost_fn)\n",
        "\n",
        "    def _z_update_L_T(self, y):\n",
        "        \"\"\"\n",
        "        Update z_{L,T} based on equation (16) with t=T:\n",
        "        z_{L,T} = (α_L,T*s_L,T + (y-λ/2)*1(t=T)) / (α_L,T + 1)\n",
        "\n",
        "        Parameters:\n",
        "        - y: target values [batch_size, n_outputs]\n",
        "        \"\"\"\n",
        "        alpha = self.rho / 2\n",
        "        l = self.L - 1  # Last layer index\n",
        "        t = self.T - 1  # Last timestep\n",
        "\n",
        "        # Calculate helper vectors for final timestep\n",
        "        _, s_l, _, _ = self._calculate_p_s_q_r(l, t)\n",
        "        # s_l is already [batch_size, n_outputs] for last layer\n",
        "\n",
        "        # Reshape y if needed\n",
        "        batch_size = s_l.shape[0]\n",
        "        n_outputs = s_l.shape[1]  # Use s_l shape since it's already correct\n",
        "        if y.shape != (batch_size, n_outputs):\n",
        "            y = y.view(batch_size, n_outputs)\n",
        "\n",
        "        # Calculate update with matched dimensions\n",
        "        numerator = (alpha * s_l) + (y - self.lambda_lagrange/2)  # All [batch_size, n_outputs]\n",
        "        denominator = alpha + 1.0\n",
        "\n",
        "        # Calculate update\n",
        "        z_update = numerator / denominator\n",
        "\n",
        "        # Define cost function according to equation (15)\n",
        "        def cost_fn(z):\n",
        "            return (torch.norm(z - y)**2 +\n",
        "                    alpha * torch.norm(z - s_l)**2 +\n",
        "                    torch.sum(self.lambda_lagrange * z))\n",
        "\n",
        "        return self.check_entries(z_update, cost_fn)\n",
        "\n",
        "    def check_entries(self, z, cost_function, params=None):\n",
        "        \"\"\"\n",
        "        Vectorized implementation of Algorithm 1\n",
        "        \"\"\"\n",
        "        # Work with a copy of z\n",
        "        z_adjusted = z.clone()\n",
        "\n",
        "        # Create mask for active neurons (z > θ)\n",
        "        active_mask = z > self.theta\n",
        "\n",
        "        # Calculate costs for current values\n",
        "        current_costs = cost_function(z_adjusted)\n",
        "\n",
        "        # Calculate costs at theta (for turning off)\n",
        "        theta_costs = cost_function(torch.full_like(z_adjusted, self.theta))\n",
        "\n",
        "        # Where z > θ and cost at θ is lower or equal, set to θ (turn off)\n",
        "        turn_off_mask = active_mask & (theta_costs <= current_costs)\n",
        "        z_adjusted[turn_off_mask] = self.theta\n",
        "\n",
        "        # Create mask for inactive neurons (z ≤ θ)\n",
        "        inactive_mask = ~active_mask\n",
        "\n",
        "        # Calculate costs at theta + ε (for turning on)\n",
        "        epsilon = 1e-6\n",
        "        theta_plus_eps_costs = cost_function(torch.full_like(z_adjusted, self.theta + epsilon))\n",
        "\n",
        "        # Where z ≤ θ and cost at θ+ε is lower, set to θ+ε (turn on)\n",
        "        turn_on_mask = inactive_mask & (theta_plus_eps_costs < current_costs)\n",
        "        z_adjusted[turn_on_mask] = self.theta + epsilon\n",
        "\n",
        "        return z_adjusted\n",
        "    # ============ lagrange multiplier update ============\n",
        "\n",
        "    def _lambda_update(self):\n",
        "        \"\"\"\n",
        "        Update Lagrange multipliers (lambda) based on equation:\n",
        "        λ^(+1) ← λ + ρ(z_{L,T} - δz_{L,T-1} - W_L a_{L-1,T})\n",
        "        \"\"\"\n",
        "        print(\"\\nDebugging _lambda_update:\")\n",
        "\n",
        "        # Parameters\n",
        "        rho = self.rho\n",
        "        delta = self.delta\n",
        "        l = self.L - 1  # Output layer index\n",
        "        t = self.T - 1  # Final timestep\n",
        "\n",
        "        # Get tensors with proper shapes\n",
        "        z_L_T = self.z[l][t]                    # [batch_size, n_outputs]\n",
        "        z_L_T_minus_1 = self.z[l][t - 1]        # [batch_size, n_outputs]\n",
        "        a_L_minus_1_T = self.a[l-1][t]          # [batch_size, hidden_dim]\n",
        "        W_L = self.W[l]                         # [n_outputs, hidden_dim]\n",
        "\n",
        "        # Calculate projection term: W_L @ a_{L-1,T}\n",
        "        projection = torch.matmul(a_L_minus_1_T, W_L.t())  # [batch_size, n_outputs]\n",
        "\n",
        "        # Calculate the full update term\n",
        "        update_term = z_L_T - delta * z_L_T_minus_1 - projection\n",
        "\n",
        "        # Update lambda\n",
        "        lambda_update = self.lambda_lagrange + rho * update_term\n",
        "\n",
        "        return lambda_update\n",
        "\n",
        "    def feed_forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Implement forward pass using SNNTorch LIF neurons.\n",
        "        Returns membrane potentials of final layer.\n",
        "\n",
        "        Parameters:\n",
        "        - inputs: [timesteps, batch_size, input_dim]\n",
        "        Returns:\n",
        "        - mem[-1]: Final layer membrane potentials [batch_size, n_outputs]\n",
        "        \"\"\"\n",
        "        # Initialize membrane potentials for each layer\n",
        "        mem = []\n",
        "        spikes = []  # Track spikes for debugging\n",
        "        for l in range(self.L):\n",
        "            if l == 0:\n",
        "                mem.append(torch.zeros(inputs.shape[1], self.hidden_dims[0], device=self.device))\n",
        "            elif l == self.L - 1:\n",
        "                mem.append(torch.zeros(inputs.shape[1], self.n_outputs, device=self.device))\n",
        "            else:\n",
        "                mem.append(torch.zeros(inputs.shape[1], self.hidden_dims[l], device=self.device))\n",
        "\n",
        "        # Create LIF neurons for each layer\n",
        "        neurons = []\n",
        "        for l in range(self.L):\n",
        "            if l < self.L - 1:\n",
        "                # Hidden layers: reset by subtraction\n",
        "                lif = snn.Leaky(\n",
        "                    beta=self.delta,\n",
        "                    threshold=self.theta,\n",
        "                    reset_mechanism=\"subtract\",\n",
        "                    learn_beta=False,\n",
        "                    learn_threshold=False\n",
        "                )\n",
        "            else:\n",
        "                # Output layer: no reset\n",
        "                lif = snn.Leaky(\n",
        "                    beta=self.delta,\n",
        "                    threshold=self.theta,\n",
        "                    reset_mechanism=\"none\",\n",
        "                    learn_beta=False,\n",
        "                    learn_threshold=False\n",
        "                )\n",
        "            neurons.append(lif)\n",
        "\n",
        "        # Process each timestep and track activations\n",
        "        for t in range(inputs.shape[0]):\n",
        "            x = inputs[t]  # Current input slice\n",
        "\n",
        "            for l in range(self.L):\n",
        "\n",
        "                # Apply weights and LIF neuron dynamics\n",
        "                x = x @ self.W[l].T  # Apply weights\n",
        "\n",
        "                spike, mem[l] = neurons[l](x, mem[l])  # Apply LIF neuron\n",
        "                spikes.append(spike)  # Track spikes\n",
        "\n",
        "\n",
        "                # Spikes become input to the next layer\n",
        "                x = spike\n",
        "\n",
        "        # Check if final layer membrane potentials seem reasonable\n",
        "        final_output = mem[-1]\n",
        "        print(f\"\\nFinal Layer Membrane Potentials - Mean: {final_output.mean():.4f}, Std: {final_output.std():.4f}\")\n",
        "        print(f\"Final Layer Potential Range - Min: {final_output.min().item():.4f}, Max: {final_output.max().item():.4f}\")\n",
        "\n",
        "        return final_output  # [batch_size, n_outputs]\n",
        "    def evaluate(self, inputs, targets):\n",
        "        \"\"\"\n",
        "        Evaluate model performance on N-MNIST dataset with detailed prediction information.\n",
        "\n",
        "        Parameters:\n",
        "        - inputs: [timesteps, batch_size, input_dim]\n",
        "        - targets: [batch_size, 10] (one-hot encoded)\n",
        "\n",
        "        Returns:\n",
        "        - loss: Cross-entropy loss\n",
        "        - predictions: Final layer output\n",
        "        \"\"\"\n",
        "        print(\"\\n=== N-MNIST Evaluation ===\")\n",
        "\n",
        "        # Get final layer activity\n",
        "        raw_predictions = self.feed_forward(inputs)  # [batch_size, n_outputs]\n",
        "        print(\"\\nFinal Layer Activity:\")\n",
        "        print(f\"Shape: {raw_predictions.shape}\")\n",
        "        print(f\"Activity Stats - Mean: {raw_predictions.mean():.4f}, Std: {raw_predictions.std():.4f}\")\n",
        "        print(f\"Activity Range - Min: {raw_predictions.min():.4f}, Max: {raw_predictions.max():.4f}\")\n",
        "\n",
        "        # Calculate predictions and true classes\n",
        "        pred_classes = raw_predictions.argmax(dim=1)  # Predicted classes\n",
        "        true_classes = targets.argmax(dim=1)          # True classes (from one-hot labels)\n",
        "\n",
        "        # Initialize confusion matrix and metrics storage\n",
        "        confusion_matrix = torch.zeros(10, 10, dtype=torch.int32)\n",
        "        metrics_per_class = []\n",
        "\n",
        "        # Display predictions count for each real class with highlight format\n",
        "        print(\"\\nDetailed Predictions for Each Real Class:\")\n",
        "        for class_idx in range(10):\n",
        "            # Mask for current class\n",
        "            class_mask = (true_classes == class_idx)\n",
        "\n",
        "            # Predictions for current class\n",
        "            predicted_for_class = pred_classes[class_mask]\n",
        "\n",
        "            # Count predictions for each possible class (0 to 9), with brackets for the current class index\n",
        "            predictions_count = []\n",
        "            for i in range(10):\n",
        "                count = (predicted_for_class == i).sum().item()\n",
        "                if i == class_idx:\n",
        "                    predictions_count.append(f\"[{count}]\")  # Highlight correct predictions with brackets\n",
        "                else:\n",
        "                    predictions_count.append(str(count))\n",
        "\n",
        "            print(f\"Real Class {class_idx} -> Prediction Counts: ({', '.join(predictions_count)})\")\n",
        "\n",
        "            # Populate confusion matrix row for real class\n",
        "            confusion_matrix[class_idx] = torch.tensor([int(predictions_count[i].strip(\"[]\")) for i in range(10)])\n",
        "\n",
        "            # Calculate metrics for current class\n",
        "            TP = confusion_matrix[class_idx, class_idx].float()\n",
        "            FP = confusion_matrix[:, class_idx].sum().float() - TP\n",
        "            FN = confusion_matrix[class_idx, :].sum().float() - TP\n",
        "\n",
        "            precision = TP / (TP + FP) if TP + FP > 0 else torch.tensor(0.0)\n",
        "            recall = TP / (TP + FN) if TP + FN > 0 else torch.tensor(0.0)\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else torch.tensor(0.0)\n",
        "\n",
        "            metrics_per_class.append({'precision': precision, 'recall': recall, 'f1': f1})\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        macro_precision = torch.stack([m['precision'] for m in metrics_per_class]).mean()\n",
        "        macro_recall = torch.stack([m['recall'] for m in metrics_per_class]).mean()\n",
        "        macro_f1 = torch.stack([m['f1'] for m in metrics_per_class]).mean()\n",
        "        accuracy = (pred_classes == true_classes).float().mean()\n",
        "\n",
        "        print(\"\\nOverall Metrics:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Macro Precision: {macro_precision:.4f}\")\n",
        "        print(f\"Macro Recall: {macro_recall:.4f}\")\n",
        "        print(f\"Macro F1-Score: {macro_f1:.4f}\")\n",
        "\n",
        "        # Calculate cross-entropy loss\n",
        "        loss = self.loss_fn(raw_predictions, true_classes)\n",
        "        print(f\"\\nLoss: {loss.item():.6f}\")\n",
        "\n",
        "        return loss, raw_predictions\n",
        "    def fit(self, inputs, targets,warm = True):\n",
        "      \"\"\"\n",
        "      Update the optimization variables following Algorithm 2 from the paper.\n",
        "      Architecture:\n",
        "      - L = 4 (3 hidden + 1 output)\n",
        "      - Layer 0: 1156 -> 128\n",
        "      - Layer 1: 128 -> 64\n",
        "      - Layer 2: 64 -> 32\n",
        "      - Layer 3: 32 -> 10\n",
        "      \"\"\"\n",
        "      print(\"\\nStarting optimization updates...\")\n",
        "      # First update hidden layers (0 to 2)\n",
        "      for l in range(self.L - 1):  # 0,1,2\n",
        "\n",
        "          # Update weights using _weight_update\n",
        "          self.W[l] = self._weight_update(l)\n",
        "\n",
        "          # Update timesteps 0 to T-2\n",
        "          for t in range(self.T-1):\n",
        "\n",
        "              if l < self.L - 2:  # Layers 0,1\n",
        "                  self.a[l][t] = self._activation_update(l, t)\n",
        "              else:  # Layer 2\n",
        "                  self.a[l][t] = self._activation_update_Lminus1(t)\n",
        "\n",
        "\n",
        "              # Update z for all hidden layers\n",
        "              self.z[l][t] = self._z_update(l, t)\n",
        "\n",
        "\n",
        "          # Handle final timestep (T-1)\n",
        "\n",
        "          if l < self.L - 2:\n",
        "              self.a[l][self.T-1] = self._activation_update_T(l)\n",
        "\n",
        "          else:  # Layer 2\n",
        "\n",
        "              self.a[l][self.T-1] = self._activation_update_Lminus1_T()\n",
        "\n",
        "\n",
        "\n",
        "          self.z[l][self.T-1] = self._z_update_T(l)\n",
        "\n",
        "\n",
        "\n",
        "      # Update output layer weights\n",
        "\n",
        "      self.W[self.L-1] = self._weight_update_L(y=targets)\n",
        "\n",
        "\n",
        "      # Update output layer z values for timesteps 0 to T-2\n",
        "      for t in range(self.T-1):\n",
        "          self.z[self.L-1][t] = self._z_update_L(t, y=targets)\n",
        "\n",
        "      # Update final timestep of output layer\n",
        "      self.z[self.L-1][self.T-1] = self._z_update_L_T(y=targets)\n",
        "\n",
        "      # Update Lagrange multiplier\n",
        "      if not warm:\n",
        "          self.lambda_lagrange = self._lambda_update()\n",
        "\n",
        "      # Evaluate current performance\n",
        "      loss, predictions = self.evaluate(inputs, targets)\n",
        "\n",
        "      return loss, predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import tonic\n",
        "import tonic.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tonic import DiskCachedDataset\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import functional as SF\n",
        "from snntorch import utils\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define transformations\n",
        "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
        "frame_transform = transforms.Compose([\n",
        "    transforms.Denoise(filter_time=10000),\n",
        "    transforms.ToFrame(sensor_size=sensor_size, time_window=1000)\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "trainset = tonic.datasets.NMNIST(save_to='./data', transform=frame_transform, train=True)\n",
        "testset = tonic.datasets.NMNIST(save_to='./data', transform=frame_transform, train=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CE8E8qJZEvPy",
        "outputId": "31764a95-4f21-4f2f-fb1f-65a6e4219489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "ddb5eaedc5c146ec81721bf79bfb31bd",
            "69432ab51d5b45f187091d7d780b65b5",
            "7c004040f79d4206993e13b6f5810ce8",
            "a8918ff6f2584f2192b438f43d48b8e6",
            "e99143355988488aa697b4328908a30a",
            "dbec077acfcc4eb9bc4075ba0ff97a88",
            "50ce3dfee9be4f9880bbd23d0c4237df",
            "1ffb4850841a4613b1f6f1d1c6bc02c8",
            "4aa07d7edc454920b42c0bcb58b6bfb9",
            "7a39dd0c13d4403990ff49cad3ab7332",
            "82cc0d7900694c3b822a0c211c048380",
            "48b496dbb46b43778bc7815fb4b440d4",
            "67155332301d46f48619f8b24a57ff05",
            "83966ad7494f42a7966880fcfc946395",
            "bf975dcd726a4bfc86846b4b6c20a509",
            "474733dd34d940f098ad001ce84fd974",
            "0ea7cac6939e413493a5675384251184",
            "423b77af118f44b9a8c576ac994766da",
            "66f89292fd8c46eb83fa03df508bdffe",
            "1c1820eda1464cd9b28e1db0a344baec",
            "03ca749668e249b190afeccd0b271879",
            "1790f671834f4b17870cfb923d952fa4"
          ]
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/1afc103f-8799-464a-a214-81bb9b1f9337 to ./data/NMNIST/train.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1011893601 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddb5eaedc5c146ec81721bf79bfb31bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/NMNIST/train.zip to ./data/NMNIST\n",
            "Downloading https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/a99d0fee-a95b-4231-ad22-988fdb0a2411 to ./data/NMNIST/test.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169674850 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48b496dbb46b43778bc7815fb4b440d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/NMNIST/test.zip to ./data/NMNIST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_nmnist_data(inputs, labels, device, n_timesteps=300):\n",
        "    batch_size = inputs.shape[0]\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    inputs = inputs[:, :n_timesteps]\n",
        "    # Reshape inputs to [timesteps, batch_size, input_dim]\n",
        "    inputs = inputs.reshape(batch_size, n_timesteps, -1).permute(1, 0, 2).float()\n",
        "    # One-hot encode labels\n",
        "    labels_onehot = torch.zeros(batch_size, 10, device=device)\n",
        "    labels_onehot.scatter_(1, labels.unsqueeze(1), 1)\n",
        "    print(f\"\\nData preparation stats:\")\n",
        "    print(f\"Input shape: {inputs.shape}\")\n",
        "    print(f\"Labels shape: {labels_onehot.shape}\")\n",
        "\n",
        "    return inputs, labels_onehot\n",
        "\n",
        "def train(model, trainloader, num_epochs):\n",
        "    \"\"\"\n",
        "    Train ADMM-SNN model\n",
        "    \"\"\"\n",
        "    # Warming phase\n",
        "    print(\"\\nWarming Phase:\")\n",
        "    warming_losses = []\n",
        "    for epoch in range(5):\n",
        "        print(f'Warming Epoch [{epoch+1}/5]')\n",
        "        epoch_losses = []\n",
        "        epoch_accuracies = []\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
        "            print(f'  Batch [{batch_idx+1}/{len(trainloader)}]')\n",
        "            # Prepare data\n",
        "            inputs, labels = prepare_nmnist_data(inputs, labels, device)\n",
        "\n",
        "            # Warming step\n",
        "            loss, predictions = model.fit(inputs, labels, True)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            pred_classes = torch.argmax(predictions, dim=1)\n",
        "            true_classes = torch.argmax(labels, dim=1)\n",
        "            accuracy = (pred_classes == true_classes).float().mean().item()\n",
        "\n",
        "            epoch_losses.append(loss)\n",
        "            epoch_accuracies.append(accuracy)\n",
        "\n",
        "        # Epoch summary\n",
        "        avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
        "        avg_acc = sum(epoch_accuracies) / len(epoch_accuracies)\n",
        "        warming_losses.append(avg_loss)\n",
        "        print(f'  Epoch Summary - Loss: {avg_loss:.6f}, Accuracy: {avg_acc:.4f}')\n",
        "\n",
        "\n",
        "    # Main training\n",
        "    print(\"\\nMain Training Phase:\")\n",
        "    training_metrics = []\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "        epoch_losses = []\n",
        "        epoch_accuracies = []\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
        "            print(f'  Batch [{batch_idx+1}/{len(trainloader)}]')\n",
        "\n",
        "            # Prepare data\n",
        "            inputs, labels = prepare_nmnist_data(inputs, labels, device)\n",
        "\n",
        "            # Training step\n",
        "            loss, predictions = model.fit(inputs, labels,False)\n",
        "\n",
        "            # Ensure predictions and labels have correct shape\n",
        "            labels = labels.t()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            pred_classes = torch.argmax(predictions, dim=1)\n",
        "            true_classes = torch.argmax(labels, dim=1)\n",
        "            accuracy = (pred_classes == true_classes).float().mean().item()\n",
        "\n",
        "            epoch_losses.append(loss)\n",
        "            epoch_accuracies.append(accuracy)\n",
        "\n",
        "\n",
        "\n",
        "        # Epoch summary\n",
        "        avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
        "        avg_acc = sum(epoch_accuracies) / len(epoch_accuracies)\n",
        "        training_metrics.append({\n",
        "            'epoch': epoch + 1,\n",
        "            'loss': avg_loss,\n",
        "            'accuracy': avg_acc\n",
        "        })\n",
        "        print(f'  Epoch Summary - Loss: {avg_loss:.6f}, Accuracy: {avg_acc:.4f}')\n",
        "\n",
        "    return warming_losses, training_metrics\n",
        "\n",
        "def evaluate(model, testloader):\n",
        "    print(\"\\nEvaluation Phase:\")\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    num_batches = 0\n",
        "    batch_metrics = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, labels) in enumerate(testloader):\n",
        "            print(f'  Batch [{batch_idx+1}/{len(testloader)}]')\n",
        "\n",
        "            # Prepare data\n",
        "            inputs, labels = prepare_nmnist_data(inputs, labels, device)\n",
        "\n",
        "            # Forward pass\n",
        "            loss, predictions = model.evaluate(inputs, labels)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            pred_classes = torch.argmax(predictions, dim=0)\n",
        "            true_classes = torch.argmax(labels, dim=0)\n",
        "            accuracy = (pred_classes == true_classes).float().mean().item()\n",
        "\n",
        "            # Store batch metrics\n",
        "            batch_metrics.append({\n",
        "                'batch': batch_idx + 1,\n",
        "                'loss': loss,\n",
        "                'accuracy': accuracy\n",
        "            })\n",
        "\n",
        "            total_loss += loss\n",
        "            total_acc += accuracy\n",
        "            num_batches += 1\n",
        "\n",
        "            print(f'    Loss: {loss:.6f}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_acc = total_acc / num_batches\n",
        "\n",
        "    print(f'\\nFinal Evaluation Results:')\n",
        "    print(f'  Average Loss: {avg_loss:.6f}')\n",
        "    print(f'  Average Accuracy: {avg_acc:.4f}')\n",
        "\n",
        "    return avg_loss, avg_acc, batch_metrics\n",
        "\n",
        "# Initialize model and training\n",
        "n_timesteps = 300\n",
        "input_dim = 2* sensor_size[0] * sensor_size[1]\n",
        "hidden_dims = [256,64]\n",
        "n_outputs = 10\n",
        "# DataLoaders\n",
        "\n",
        "\n",
        "# Create DataLoaders with the subsets\n",
        "batch_size = 64\n",
        "# Calculate size of 20% of data\n",
        "train_size = int(0.2 * len(trainset)) // batch_size * batch_size\n",
        "test_size = int(0.2 * len(testset)) // batch_size * batch_size\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "train_subset = Subset(trainset, torch.randperm(len(trainset))[:train_size])\n",
        "test_subset = Subset(testset, torch.randperm(len(testset))[:test_size])\n",
        "\n",
        "\n",
        "\n",
        "trainloader = DataLoader(train_subset,\n",
        "                        batch_size=batch_size,\n",
        "                        collate_fn=tonic.collation.PadTensors(),\n",
        "                        shuffle=True)\n",
        "testloader = DataLoader(test_subset,\n",
        "                       batch_size=batch_size,\n",
        "                       collate_fn=tonic.collation.PadTensors())\n",
        "\n",
        "print(f\"Original training set size: {len(trainset)}\")\n",
        "print(f\"training set size: {len(train_subset)}\")\n",
        "print(f\"Original test set size: {len(testset)}\")\n",
        "print(f\"test set size: {len(test_subset)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZZTYxOQZEwKx",
        "outputId": "da7f5f72-f628-47fc-8343-38764ba47ee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original training set size: 60000\n",
            "training set size: 11968\n",
            "Original test set size: 10000\n",
            "test set size: 1984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "rho = 0.25\n",
        "delta = 0.85\n",
        "theta = 0.2\n",
        "\n",
        "\n",
        "# Create model\n",
        "print(\"\\nInitializing model...\")\n",
        "model = ADMM_SNN(\n",
        "    n_samples=batch_size,\n",
        "    n_timesteps=n_timesteps,\n",
        "    input_dim=input_dim,\n",
        "    hidden_dims=hidden_dims,  # Changed final dimension to 10\n",
        "    n_outputs=10,\n",
        "    rho=rho,\n",
        "    delta=delta,\n",
        "    theta=theta\n",
        ")\n",
        "print(model)\n",
        "\n",
        "\n",
        "# Train model\n",
        "print(\"\\nStarting training process...\")\n",
        "num_epochs = 20\n",
        "warming_losses, training_metrics = train(model, trainloader, num_epochs)\n",
        "\n",
        "# Evaluate model\n",
        "print(\"\\nEvaluating model...\")\n",
        "test_loss, test_acc, test_metrics = evaluate(model, testloader)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nTraining Summary:\")\n",
        "print(f\"  Warming phase final loss: {warming_losses[-1]:.6f}\")\n",
        "print(f\"  Training final loss: {training_metrics[-1]['loss']:.6f}\")\n",
        "print(f\"  Training final accuracy: {training_metrics[-1]['accuracy']:.4f}\")\n",
        "print(\"\\nTest Results:\")\n",
        "print(f\"  Test Loss: {test_loss:.6f}\")\n",
        "print(f\"  Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "5NuMotZ4FSLu",
        "outputId": "8d06c895-82b5-4e61-d03e-b28b672027b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initializing model...\n",
            "\n",
            "Model Initialization Details:\n",
            "Device: cpu\n",
            "Previous activation shape: torch.Size([300, 64, 2312])\n",
            "Weight layer 0 shape: torch.Size([256, 2312])\n",
            "Weight layer 1 shape: torch.Size([64, 256])\n",
            "Weight layer 2 shape: torch.Size([10, 64])\n",
            "z[0] shape: torch.Size([300, 64, 256])\n",
            "z[1] shape: torch.Size([300, 64, 64])\n",
            "z[2] shape: torch.Size([300, 64, 10])\n",
            "a[0] shape: torch.Size([300, 64, 256])\n",
            "a[1] shape: torch.Size([300, 64, 64])\n",
            "a[2] shape: torch.Size([300, 64, 10])\n",
            "lambda[0] shape: torch.Size([10])\n",
            "ADMM SNN Model Structure:\n",
            " - rho: 0.25, delta: 0.85, theta: 0.2\n",
            " - Number of timesteps: 300\n",
            " - Input dimension: torch.Size([300, 64, 2312])\n",
            " - Hidden layers: [torch.Size([256, 2312]), torch.Size([64, 256]), torch.Size([10, 64])]\n",
            " - Output dimension (Lagrange Multiplier): torch.Size([64, 10])\n",
            " - self.L : 3\n",
            " - self.T : 300\n",
            "\n",
            "\n",
            "Starting training process...\n",
            "\n",
            "Warming Phase:\n",
            "Warming Epoch [1/5]\n",
            "  Batch [1/187]\n",
            "\n",
            "Data preparation stats:\n",
            "Input shape: torch.Size([300, 64, 2312])\n",
            "Labels shape: torch.Size([64, 10])\n",
            "\n",
            "Starting optimization updates...\n",
            "\n",
            "=== N-MNIST Evaluation ===\n",
            "\n",
            "Final Layer Membrane Potentials - Mean: 0.2107, Std: 6.3060\n",
            "Final Layer Potential Range - Min: -31.9631, Max: 28.5688\n",
            "\n",
            "Final Layer Activity:\n",
            "Shape: torch.Size([64, 10])\n",
            "Activity Stats - Mean: 0.2107, Std: 6.3060\n",
            "Activity Range - Min: -31.9631, Max: 28.5688\n",
            "\n",
            "Detailed Predictions for Each Real Class:\n",
            "Real Class 0 -> Prediction Counts: ([0], 0, 2, 6, 0, 0, 0, 0, 0, 0)\n",
            "Real Class 1 -> Prediction Counts: (0, [0], 2, 5, 0, 0, 0, 1, 1, 1)\n",
            "Real Class 2 -> Prediction Counts: (0, 1, [0], 2, 0, 0, 0, 1, 0, 0)\n",
            "Real Class 3 -> Prediction Counts: (0, 1, 3, [5], 0, 0, 0, 0, 2, 0)\n",
            "Real Class 4 -> Prediction Counts: (0, 1, 1, 2, [0], 0, 0, 0, 2, 0)\n",
            "Real Class 5 -> Prediction Counts: (0, 1, 1, 1, 0, [0], 1, 1, 0, 0)\n",
            "Real Class 6 -> Prediction Counts: (1, 1, 0, 0, 0, 0, [1], 0, 3, 0)\n",
            "Real Class 7 -> Prediction Counts: (0, 1, 1, 1, 0, 0, 2, [1], 2, 0)\n",
            "Real Class 8 -> Prediction Counts: (0, 0, 1, 1, 1, 0, 0, 1, [0], 0)\n",
            "Real Class 9 -> Prediction Counts: (0, 1, 0, 1, 0, 0, 0, 0, 0, [0])\n",
            "\n",
            "Overall Metrics:\n",
            "Accuracy: 0.1094\n",
            "Macro Precision: 0.1028\n",
            "Macro Recall: 0.0746\n",
            "Macro F1-Score: 0.0761\n",
            "\n",
            "Loss: 8.028079\n",
            "  Batch [2/187]\n",
            "\n",
            "Data preparation stats:\n",
            "Input shape: torch.Size([300, 64, 2312])\n",
            "Labels shape: torch.Size([64, 10])\n",
            "\n",
            "Starting optimization updates...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1d208b4f621e>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStarting training process...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mwarming_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-1ff3ec179f0f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, num_epochs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Warming step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# Calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-eb7b2f75e6f5>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, targets, warm)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0;31m# Update weights using _weight_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weight_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m           \u001b[0;31m# Update timesteps 0 to T-2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-eb7b2f75e6f5>\u001b[0m in \u001b[0;36m_weight_update\u001b[0;34m(self, l)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mx_l_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mnumerator\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bf,bp->fp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_l_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_l_minus_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0mdenominator\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bp,bq->pq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_l_minus_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_l_minus_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     r\"\"\"einsum(equation, *operands) -> Tensor\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}