{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8mApB33CrgdqVIeb6WkgT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "676da2c7badb46e886cdb664726f2bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_373883c1b357489d95cabcaa0b56fbd6",
              "IPY_MODEL_517d5ee73b1e4181824d64338427cc26",
              "IPY_MODEL_0848d174c8bf4279bb74d04bdd36b19d"
            ],
            "layout": "IPY_MODEL_632b7a57e54047078e8ff39da33bc29d"
          }
        },
        "373883c1b357489d95cabcaa0b56fbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a619d4b26d44d55be993fb235fa64bf",
            "placeholder": "​",
            "style": "IPY_MODEL_714d8af279d64d0c81ddf3a7143dc175",
            "value": ""
          }
        },
        "517d5ee73b1e4181824d64338427cc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96a60f8cce004a6d80c0520a2e566044",
            "max": 1011893601,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ab6ff6e3ca74a8eb0d85e6846795e03",
            "value": 1011893601
          }
        },
        "0848d174c8bf4279bb74d04bdd36b19d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7220ef8dab5640d98ad77d449d850705",
            "placeholder": "​",
            "style": "IPY_MODEL_4b6e540570f6448eba23fc75ccdd8deb",
            "value": " 1011894272/? [00:30&lt;00:00, 32496510.66it/s]"
          }
        },
        "632b7a57e54047078e8ff39da33bc29d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a619d4b26d44d55be993fb235fa64bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "714d8af279d64d0c81ddf3a7143dc175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96a60f8cce004a6d80c0520a2e566044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ab6ff6e3ca74a8eb0d85e6846795e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7220ef8dab5640d98ad77d449d850705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b6e540570f6448eba23fc75ccdd8deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0270f0433dd47faa7f08b7bf372b933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf296dbdabc349e6bf9478ff8c8ee60c",
              "IPY_MODEL_c0371dd8f81f4d79832eef3c98ed7a22",
              "IPY_MODEL_cdd54fd8ca37444da16484695e8f86f4"
            ],
            "layout": "IPY_MODEL_48af29e08ef4477ca15c2135e7231f90"
          }
        },
        "cf296dbdabc349e6bf9478ff8c8ee60c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33eee554698e442d9cf7756a7cb7eab6",
            "placeholder": "​",
            "style": "IPY_MODEL_442e2a05ecc54a1eb97b56ae22dd7de5",
            "value": ""
          }
        },
        "c0371dd8f81f4d79832eef3c98ed7a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c27db1a797644dcab2cac310d02c337",
            "max": 169674850,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75d78899265e47e2946687578e6d9c92",
            "value": 169674850
          }
        },
        "cdd54fd8ca37444da16484695e8f86f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a2210baf46f40de818d6dad3ff9ba84",
            "placeholder": "​",
            "style": "IPY_MODEL_61bf99e9712748bbad4859b934a21127",
            "value": " 169675776/? [00:06&lt;00:00, 31748007.05it/s]"
          }
        },
        "48af29e08ef4477ca15c2135e7231f90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33eee554698e442d9cf7756a7cb7eab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "442e2a05ecc54a1eb97b56ae22dd7de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c27db1a797644dcab2cac310d02c337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d78899265e47e2946687578e6d9c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a2210baf46f40de818d6dad3ff9ba84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61bf99e9712748bbad4859b934a21127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ergysmedaunipd/thesis/blob/main/ThesisUnipdSNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tonic\n",
        "!pip install snntorch\n",
        "!pip install psutil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc3-4tqnv5AS",
        "outputId": "3821303a-ec4c-4096-b8e4-a08c8340c45d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tonic\n",
            "  Downloading tonic-1.5.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from tonic) (1.26.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from tonic) (3.12.1)\n",
            "Collecting importRosbag>=1.0.4 (from tonic)\n",
            "  Downloading importRosbag-1.0.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tonic) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tonic) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from tonic) (4.12.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from tonic) (0.10.2.post1)\n",
            "Collecting pbr (from tonic)\n",
            "  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting expelliarmus (from tonic)\n",
            "  Downloading expelliarmus-1.1.12-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from importRosbag>=1.0.4->tonic) (75.1.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa->tonic) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->tonic) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->tonic) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->tonic) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->tonic) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa->tonic) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->tonic) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic) (2024.8.30)\n",
            "Downloading tonic-1.5.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importRosbag-1.0.4-py3-none-any.whl (28 kB)\n",
            "Downloading expelliarmus-1.1.12-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m938.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pbr, importRosbag, expelliarmus, tonic\n",
            "Successfully installed expelliarmus-1.1.12 importRosbag-1.0.4 pbr-6.1.0 tonic-1.5.0\n",
            "Collecting snntorch\n",
            "  Downloading snntorch-0.9.1-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.5.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from snntorch) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.26.4)\n",
            "Collecting nir (from snntorch)\n",
            "  Downloading nir-1.0.4-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting nirtorch (from snntorch)\n",
            "  Downloading nirtorch-1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.1.0->snntorch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (2.8.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from nir->snntorch) (3.12.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->snntorch) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->snntorch) (3.0.2)\n",
            "Downloading snntorch-0.9.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nir-1.0.4-py3-none-any.whl (18 kB)\n",
            "Downloading nirtorch-1.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: nir, nirtorch, snntorch\n",
            "Successfully installed nir-1.0.4 nirtorch-1.0 snntorch-0.9.1\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zcOCVUH7r4kE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "import time\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "\n",
        "\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class ADMM_SNN:\n",
        "    \"\"\" Class for ADMM Neural Network. \"\"\"\n",
        "\n",
        "    def __init__(self, n_samples: int, n_timesteps: int, input_dim: int, hidden_dims: List[int], n_outputs: int, rho: float, delta: float, theta: float):\n",
        "        \"\"\"\n",
        "        Initialize the ADMM-SNN model.\n",
        "\n",
        "        Parameters:\n",
        "        n_samples (int): Number of samples in the batch.\n",
        "        n_timesteps (int): Number of timesteps.\n",
        "        input_dim (int): Dimension of the input features.\n",
        "        hidden_dims (List[int]): List of hidden layer dimensions.\n",
        "        n_outputs (int): Number of output classes.\n",
        "        rho (float): ADMM penalty parameter.\n",
        "        delta (float): Decay factor for the intermediate variables (z).\n",
        "        theta (float): Activation threshold for the spiking neurons.\n",
        "        \"\"\"\n",
        "        # Define the device to run the model on (GPU if available)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Store model parameters\n",
        "        self.n_samples = n_samples\n",
        "        self.n_timesteps = n_timesteps\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dims = hidden_dims\n",
        "        self.n_outputs = n_outputs\n",
        "\n",
        "\n",
        "        # Loss function for training\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Hyperparameters for ADMM-SNN\n",
        "        self.rho = rho             # ADMM penalty parameter\n",
        "        self.delta = delta         # Decay factor for z updates\n",
        "        self.theta = theta         # Activation threshold for spiking neurons\n",
        "\n",
        "        # Model architecture specifications\n",
        "        self.L = len(hidden_dims) + 1  # Number of hidden layers\n",
        "        self.T = n_timesteps       # Number of timesteps in each forward pass\n",
        "\n",
        "        # Initialize initial activations (a0) as a tensor with zero values\n",
        "        self.a_minus_one = torch.zeros( (n_timesteps, n_samples, input_dim)).to(self.device)\n",
        "\n",
        "        # Initialize weights (W) for each layer in hidden_dims\n",
        "        self.W = []\n",
        "        # First hidden layer (input -> first hidden)\n",
        "        self.W.append(torch.normal(0, 0.01, (hidden_dims[0], input_dim)).to(self.device))\n",
        "\n",
        "        # Other hidden layers\n",
        "        for i in range(1, len(hidden_dims)):\n",
        "            self.W.append(torch.normal(0, 0.01, (hidden_dims[i], hidden_dims[i-1])).to(self.device))\n",
        "\n",
        "        # Output layer\n",
        "        self.W.append(torch.normal(0, 0.01, (n_outputs, hidden_dims[-1])).to(self.device))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Initialize intermediate variables (z) for each layer and timestep\n",
        "        self.z = []\n",
        "        # Hidden layers\n",
        "        for hidden_dim in hidden_dims:\n",
        "            self.z.append(torch.rand((n_timesteps, n_samples, hidden_dim)).to(self.device))\n",
        "        # Output layer\n",
        "        self.z.append(torch.rand((n_timesteps, n_samples, n_outputs)).to(self.device))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Initialize activations (a) for each layer and timestep (except output)\n",
        "        self.a = []\n",
        "        for hidden_dim in hidden_dims:\n",
        "            self.a.append(torch.rand((n_timesteps, n_samples, hidden_dim)).to(self.device))\n",
        "\n",
        "\n",
        "\n",
        "        # Initialize Lagrange multipliers (lambda) for the output layer\n",
        "        self.lambda_lagrange = torch.ones((n_samples, n_outputs)).to(self.device)\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        model_str = \"ADMM SNN Model Structure:\\n\"\n",
        "        model_str += f\" - rho: {self.rho}, delta: {self.delta}, theta: {self.theta}\\n\"\n",
        "        model_str += f\" - Number of timesteps: {self.T}\\n\"\n",
        "        model_str += f\" - Input dimension: {self.a_minus_one.size()}\\n\"\n",
        "        model_str += f\" - Hidden layers: {[w.shape for w in self.W]}\\n\"\n",
        "        model_str += f\" - Output dimension (Lagrange Multiplier): {self.lambda_lagrange.size()}\\n\"\n",
        "        model_str += f\" - self.L : {self.L }\\n\"\n",
        "        model_str += f\" - self.T : {self.T }\\n\"\n",
        "\n",
        "        \"\"\"Helper method to print shapes of initialized tensors\"\"\"\n",
        "        print(f\"\\nModel Initialization Details:\")\n",
        "        print(f\"Device: {self.device}\")\n",
        "        print(f\"Previous activation shape: {self.a_minus_one.shape}\")\n",
        "\n",
        "        for i, w in enumerate(self.W):\n",
        "            print(f\"Weight layer {i} shape: {w.shape}\")\n",
        "\n",
        "        for i, z_layer in enumerate(self.z):\n",
        "            print(f\"z[{i}] shape: {z_layer.shape}\")\n",
        "\n",
        "        for i, a_layer in enumerate(self.a):\n",
        "            print(f\"a[{i}] shape: {a_layer.shape}\")\n",
        "\n",
        "        print(f\"lambda shape: {self.lambda_lagrange.shape}\")\n",
        "\n",
        "        return model_str\n",
        "\n",
        "    def _heaviside(self, z):\n",
        "        \"\"\"\n",
        "        Implement the Heaviside function to calculate activations based on a threshold.\n",
        "        This function returns 1 where z meets or exceeds the threshold and 0 otherwise.\n",
        "\n",
        "        Parameters:\n",
        "        z (torch.Tensor): The input tensor representing the intermediate variable z at layer l and time t.\n",
        "\n",
        "        Returns:\n",
        "        torch.Tensor: A tensor of the same shape as z with values 0 or 1, based on whether each element\n",
        "                      in z is above or below the threshold self.theta.\n",
        "        \"\"\"\n",
        "        # Apply the Heaviside step function:\n",
        "        # Convert continuous values in z to binary values (0 or 1) based on self.theta\n",
        "        # - Returns 1 where z >= theta (neuron spikes).\n",
        "        # - Returns 0 where z < theta (neuron does not spike).\n",
        "        return (z >= self.theta).float()\n",
        "\n",
        "\n",
        "    # ============ W_{l} update functions ============\n",
        "    def _weight_update(self, l: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Update weights for layers 1 to L-1 following equation (4) from the paper:\n",
        "        W_l = (sum_t alpha_l,t * x_l,t * a_l-1,t^T)(sum_t alpha_l,t * a_l-1,t * a_l-1,t^T)^-1\n",
        "\n",
        "        Args:\n",
        "            l: Layer index\n",
        "        Returns:\n",
        "            Updated weight matrix for layer l\n",
        "        \"\"\"\n",
        "        alpha = self.rho / 2  # Following paper's simplified alpha_l,t = rho/2\n",
        "        z_l = self.z[l]  # [timesteps, batch, features_out]\n",
        "        a_prev = self.a[l-1] if l > 0 else self.a_minus_one  # [timesteps, batch, features_in]\n",
        "\n",
        "        n_timesteps, batch_size, n_features_out = z_l.shape\n",
        "        _, _, n_features_in = a_prev.shape\n",
        "\n",
        "        # Initialize accumulator tensors\n",
        "        x_a_sum = torch.zeros((n_features_out, n_features_in), device=self.device)\n",
        "        a_a_sum = torch.zeros((n_features_in, n_features_in), device=self.device)\n",
        "\n",
        "        for t in range(n_timesteps):\n",
        "            # Construct x_l,t according to paper definition\n",
        "            if t == 0:\n",
        "                x_l_t = z_l[0]  # First timestep\n",
        "            else:\n",
        "                # x_l,t = z_l,t - δz_l,t-1 + θa_l,t-1\n",
        "                x_l_t = z_l[t] - self.delta * z_l[t-1] + self.theta * self.a[l][t-1]\n",
        "\n",
        "            # Update sums using einsum for better efficiency\n",
        "            x_a_sum += alpha * torch.einsum('bf,bp->fp', x_l_t, a_prev[t])\n",
        "            a_a_sum += alpha * torch.einsum('bp,bq->pq', a_prev[t], a_prev[t])\n",
        "\n",
        "\n",
        "        eps = 1e-6\n",
        "        a_a_sum += eps * torch.eye(n_features_in, device=self.device)\n",
        "\n",
        "        # Return W_l = x_a_sum @ (a_a_sum)^-1\n",
        "        return x_a_sum @ torch.inverse(a_a_sum)\n",
        "\n",
        "    def _weight_update_L(self, y: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Update weights for the final layer L following equation (6) from the paper:\n",
        "        W_L = (-λ/2 * a_L-1,T^T + sum_t alpha_L,t * x_L,t * a_L-1,t^T)(sum_t alpha_L,t * a_L-1,t * a_L-1,t^T)^-1\n",
        "\n",
        "        Args:\n",
        "            y: Target values [batch, n_outputs]\n",
        "        Returns:\n",
        "            Updated weight matrix for output layer\n",
        "        \"\"\"\n",
        "        alpha = self.rho / 2\n",
        "        z_L = self.z[-1]  # Last layer's z values\n",
        "        a_L_minus_1 = self.a[-2]  # Second to last layer's activations\n",
        "\n",
        "        n_timesteps, batch_size, n_features_out = z_L.shape\n",
        "        _, _, n_features_in = a_L_minus_1.shape\n",
        "\n",
        "        # Calculate λ term from equation (6)\n",
        "        lambda_term = -0.5 * torch.einsum('bf,bp->fp',\n",
        "                                        self.lambda_lagrange,\n",
        "                                        a_L_minus_1[-1])  # Use last timestep\n",
        "\n",
        "        # Initialize accumulator tensors\n",
        "        x_a_sum = torch.zeros((n_features_out, n_features_in), device=self.device)\n",
        "        a_a_sum = torch.zeros((n_features_in, n_features_in), device=self.device)\n",
        "\n",
        "        for t in range(n_timesteps):\n",
        "            # Construct x_L,t according to paper definition for output layer\n",
        "            if t == 0:\n",
        "                x_L_t = z_L[0]\n",
        "            else:\n",
        "                # Note: output layer doesn't include θa term\n",
        "                x_L_t = z_L[t] - self.delta * z_L[t-1]\n",
        "\n",
        "            # Update sums\n",
        "            x_a_sum += alpha * torch.einsum('bf,bp->fp', x_L_t, a_L_minus_1[t])\n",
        "            a_a_sum += alpha * torch.einsum('bp,bq->pq', a_L_minus_1[t], a_L_minus_1[t])\n",
        "\n",
        "        # Add small identity matrix for numerical stability\n",
        "        eps = 1e-6\n",
        "        a_a_sum += eps * torch.eye(n_features_in, device=self.device)\n",
        "\n",
        "        # Return W_L = (lambda_term + x_a_sum) @ (a_a_sum)^-1\n",
        "        return (lambda_term + x_a_sum) @ torch.inverse(a_a_sum)\n",
        "\n",
        "\n",
        "    # ============ a_{l,t} update functions ============\n",
        "    # Activation update for l=1,...,L-2, t=1,...,T-1 (Equation 8)\n",
        "    def _calculate_u_w_v(self, l, t):\n",
        "        \"\"\"\n",
        "        Calculate helper vectors u_l, v_l, w_l\n",
        "        \"\"\"\n",
        "        z_l = self.z[l]\n",
        "        a_l = self.a[l]\n",
        "        a_l_minus_1 = self.a[l-1] if l > 0 else self.a_minus_one\n",
        "\n",
        "        # Calculate u_l[t]\n",
        "        if t == 0:\n",
        "            u_l_t = z_l[0]\n",
        "        else:\n",
        "            u_l_t = z_l[t] - self.delta * z_l[t-1]\n",
        "\n",
        "        # Calculate v_l[t]\n",
        "        if t == 0:\n",
        "            v_l_t = u_l_t\n",
        "        else:\n",
        "            v_l_t = u_l_t + self.theta * a_l[t-1]\n",
        "\n",
        "        # Calculate w_l[t]\n",
        "        projected_a = torch.matmul(a_l_minus_1[t], self.W[l].t())\n",
        "        w_l_t = u_l_t - projected_a\n",
        "\n",
        "        return u_l_t, w_l_t, v_l_t\n",
        "\n",
        "    def _activation_update(self, l, t):\n",
        "        \"\"\"\n",
        "        Update activations based on equation (8)\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = self.rho / 2\n",
        "        beta = alpha\n",
        "\n",
        "        # Get dimensions\n",
        "        batch_size = self.z[l][t].shape[0]  # 256\n",
        "        n_features = self.z[l][t].shape[1]  # 128 for layer 0\n",
        "        W_next = self.W[l+1]  # [64, 128] for layer 0->1\n",
        "\n",
        "        # Matrix terms\n",
        "        I = torch.eye(n_features, device=self.device)\n",
        "        term1 = (self.theta ** 2) * alpha * I\n",
        "        term2 = alpha * W_next.t() @ W_next  # [128, 64] @ [64, 128] -> [128, 128]\n",
        "        term3 = beta * I\n",
        "\n",
        "        matrix_to_invert = term1 + term2 + term3\n",
        "\n",
        "        # Calculate RHS terms\n",
        "        _, w_next, _ = self._calculate_u_w_v(l, t+1)\n",
        "        rhs_term1 = -self.theta * alpha * w_next  # [256, 128]\n",
        "\n",
        "        _, _, v_next = self._calculate_u_w_v(l+1, t)  # v_next shape: [256, 64]\n",
        "        # Fix: multiply in correct order\n",
        "        rhs_term2 = alpha * torch.matmul(v_next, W_next)  # [256, 64] @ [64, 128] -> [256, 128]\n",
        "\n",
        "        heaviside_term = self._heaviside(self.z[l][t])  # [256, 128]\n",
        "        rhs_term3 = beta * heaviside_term\n",
        "\n",
        "        # Combine RHS terms\n",
        "        rhs = rhs_term1 + rhs_term2 + rhs_term3\n",
        "\n",
        "        # Solve the system\n",
        "        updated_a = torch.linalg.solve(matrix_to_invert, rhs.t()).t()\n",
        "\n",
        "        return updated_a\n",
        "\n",
        "    # Activation update for l=L-1, t=1,...,T-1 (Equation 10)\n",
        "    def _activation_update_T(self, l):\n",
        "        \"\"\"\n",
        "        Update activations for l=1,...,L-2 at t=T based on equation (9):\n",
        "        a_l,T = (α_l+1,t*W_{l+1}^T*W_{l+1} + β_l,t*I)^{-1} *\n",
        "                (α_l+1,t*W_{l+1}^T*v_{l+1,t} + β_l,t*h_l(z_l,t))\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = self.rho / 2\n",
        "        beta = alpha\n",
        "\n",
        "        # Get dimensions\n",
        "        batch_size = self.z[l][self.T-1].shape[0]  # 256\n",
        "        n_features = self.z[l][self.T-1].shape[1]  # current layer features\n",
        "        W_next = self.W[l+1]\n",
        "\n",
        "        # Calculate matrix to invert: α_l+1,t*W_{l+1}^T*W_{l+1} + β_l,t*I\n",
        "        term1 = alpha * W_next.t() @ W_next\n",
        "        term2 = beta * torch.eye(n_features, device=self.device)\n",
        "        matrix_to_invert = term1 + term2\n",
        "\n",
        "        # Calculate v_{l+1,t} for the first RHS term\n",
        "        _, _, v_next = self._calculate_u_w_v(l+1, self.T-1)\n",
        "        # Fix: multiply in correct order\n",
        "        rhs_term1 = alpha * torch.matmul(v_next, W_next)  # [256, 64] @ [64, 128] -> [256, 128]\n",
        "\n",
        "        # Calculate h_l(z_l,t) for second RHS term\n",
        "        heaviside_term = self._heaviside(self.z[l][self.T-1])  # [256, 128]\n",
        "        rhs_term2 = beta * heaviside_term\n",
        "\n",
        "        # Combine RHS terms\n",
        "        rhs = rhs_term1 + rhs_term2\n",
        "\n",
        "        # Solve the system\n",
        "        updated_a = torch.linalg.solve(matrix_to_invert, rhs.t()).t()\n",
        "\n",
        "        return updated_a\n",
        "\n",
        "    def _activation_update_Lminus1(self, t):\n",
        "        \"\"\"\n",
        "        Update activations for l=L-1 based on equation (11):\n",
        "        a_L-1,t = (α_L,t*W_L^T*W_L + β_L-1,t*I)^{-1} *\n",
        "                  (W_L^T(α_L,t*u_L,t - λ/2*1(t=T)) + β_L-1,t*h_L-1(z_L-1,t - θ))\n",
        "        \"\"\"\n",
        "\n",
        "        alpha = self.rho / 2\n",
        "        beta = alpha\n",
        "        l = self.L - 2  # L-1 in zero-based indexing\n",
        "        # Get dimensions\n",
        "        batch_size = self.z[l][t].shape[0]\n",
        "        n_features = self.z[l][t].shape[1]\n",
        "        W_L = self.W[l]\n",
        "\n",
        "        # Calculate matrix to invert: α_L,t*W_L^T*W_L + β_L-1,t*I\n",
        "        term1 = alpha * W_L.t() @ W_L\n",
        "        term2 = beta * torch.eye(n_features, device=self.device)\n",
        "        matrix_to_invert = term1 + term2\n",
        "\n",
        "        # Calculate u_L,t\n",
        "        u_L, _, _ = self._calculate_u_w_v(l, t)\n",
        "\n",
        "        # Calculate first part of RHS: W_L^T(α_L,t*u_L,t)\n",
        "        # Transpose u_L to match W_L dimensions\n",
        "        rhs_term1 = alpha * (W_L.t() @ u_L.t()).t()  # Resulting in shape [batch_size, n_features]\n",
        "\n",
        "        # Calculate h_L-1(z_L-1,t - θ)\n",
        "        heaviside_term = self._heaviside(self.z[l][t] - self.theta)\n",
        "        rhs_term2 = beta * heaviside_term\n",
        "\n",
        "        # Combine RHS terms\n",
        "        rhs = rhs_term1 + rhs_term2\n",
        "\n",
        "        # Solve the system\n",
        "        updated_a = torch.linalg.solve(matrix_to_invert, rhs.t()).t()\n",
        "\n",
        "        return updated_a\n",
        "    def _activation_update_Lminus1_T(self):\n",
        "        \"\"\"\n",
        "        Update activations for l=L-1 at t=T based on equation (11) with t=T:\n",
        "        a_L-1,T = (α_L,T*W_L^T*W_L + β_L-1,T*I)^{-1} *\n",
        "                  (W_L^T(α_L,T*u_L,T - λ/2) + β_L-1,T*h_L-1(z_L-1,T - θ))\n",
        "        \"\"\"\n",
        "        alpha = self.rho / 2\n",
        "        beta = alpha\n",
        "        l = self.L - 2  # L-1 in zero-based indexing\n",
        "        t = self.T - 1  # T in zero-based indexing\n",
        "\n",
        "        # Get dimensions\n",
        "        batch_size = self.z[l][t].shape[0]  # Should be 64\n",
        "        n_features = self.z[l][t].shape[1]  # Should be 64 (hidden dim)\n",
        "        W_L = self.W[l+1]  # Should be [10, 64]\n",
        "\n",
        "\n",
        "        # Calculate matrix to invert: α_L,T*W_L^T*W_L + β_L-1,T*I\n",
        "        term1 = alpha * W_L.t() @ W_L  # [64, 10] @ [10, 64] -> [64, 64]\n",
        "        term2 = beta * torch.eye(n_features, device=self.device)\n",
        "        matrix_to_invert = term1 + term2  # [64, 64]\n",
        "\n",
        "        # Calculate u_L,T for final timestep\n",
        "        u_L, _, _ = self._calculate_u_w_v(l, t)  # Shape: [64, 64]\n",
        "\n",
        "        # Reshape lambda to match batch size and features\n",
        "        lambda_term = self.lambda_lagrange / 2  # [64, 10]\n",
        "\n",
        "        # Calculate W_L^T(α_L,T*u_L,T - λ/2)\n",
        "        # First, project u_L to output dimension\n",
        "        u_L_projected = u_L @ W_L.t()  # [64, 64] @ [64, 10] -> [64, 10]\n",
        "\n",
        "        # Now subtract lambda_term\n",
        "        diff = alpha * u_L_projected - lambda_term  # [64, 10]\n",
        "\n",
        "        # Project back using W_L.t()\n",
        "        rhs_term1 = diff @ W_L  # [64, 10] @ [10, 64] -> [64, 64]\n",
        "\n",
        "        # Calculate h_L-1(z_L-1,T - θ)\n",
        "        heaviside_term = self._heaviside(self.z[l][t] - self.theta)  # [64, 64]\n",
        "        rhs_term2 = beta * heaviside_term\n",
        "\n",
        "        # Combine RHS terms\n",
        "        rhs = rhs_term1 + rhs_term2  # [64, 64]\n",
        "\n",
        "        # Solve the system\n",
        "        updated_a = torch.linalg.solve(matrix_to_invert, rhs.t()).t()\n",
        "\n",
        "\n",
        "        return updated_a\n",
        "     # ============ z_{l,t} update functions ============\n",
        "    def _calculate_p_s_q_r(self, l, t):\n",
        "        \"\"\"\n",
        "        Calculate helper vectors defined in paper:\n",
        "        p_l = W_l[a_l-1,1, ..., a_l-1,T]\n",
        "        s_l = p_l + δ[0, z_l,1, ..., z_l,T-1]\n",
        "        q_l = s_l - θ[0, a_l,1, ..., a_l,T-1]\n",
        "        r_l = -p_l + z_l\n",
        "        \"\"\"\n",
        "        # Get previous layer activations and current layer data\n",
        "        a_l_minus_1 = self.a[l-1] if l > 0 else self.a_minus_one\n",
        "\n",
        "        # Calculate p_l: project previous layer activations through weights\n",
        "        p_l = torch.matmul(a_l_minus_1[t], self.W[l].t())  # [batch, features]\n",
        "\n",
        "        # Calculate s_l: add decayed previous z values\n",
        "        if t == 0:\n",
        "            s_l = p_l\n",
        "        else:\n",
        "            s_l = p_l + self.delta * self.z[l][t-1]\n",
        "\n",
        "        # Calculate q_l: subtract theta-weighted activations if available\n",
        "        if t == 0:\n",
        "            q_l = s_l\n",
        "        else:\n",
        "            q_l = s_l - self.theta * self.a[l][t-1] if l < len(self.a) else s_l\n",
        "\n",
        "        # Calculate r_l: negative p_l plus current z\n",
        "        r_l = -p_l + self.z[l][t]\n",
        "\n",
        "        return p_l, s_l, q_l, r_l\n",
        "\n",
        "    def _z_update(self, l, t):\n",
        "        \"\"\"\n",
        "        Update z_{l,t} for l=1,...,L-1 and t=1,...,T-1\n",
        "        z_{l,t} = (α_l,t*q_l,t + α_l,t+1*δ(r_l,t+1 + θa_l,t)*1(t<T)) / (α_l,t + δ²α_l,t+1*1(t<T))\n",
        "        \"\"\"\n",
        "        alpha = self.rho / 2\n",
        "\n",
        "        # Calculate helper vectors\n",
        "        _, _, q_l, r_l = self._calculate_p_s_q_r(l, t)\n",
        "\n",
        "        # Calculate initial z update (before check_entries)\n",
        "        numerator = alpha * q_l\n",
        "\n",
        "        if t < self.T - 1:\n",
        "            _, _, _, r_next = self._calculate_p_s_q_r(l, t+1)\n",
        "            second_term = alpha * self.delta * (r_next + self.theta * self.a[l][t])\n",
        "            numerator = numerator + second_term\n",
        "\n",
        "        denominator = alpha\n",
        "        if t < self.T - 1:\n",
        "            denominator = denominator + (self.delta ** 2) * alpha\n",
        "\n",
        "        # Initial z update\n",
        "        z_update = numerator / denominator\n",
        "\n",
        "        # Apply check_entries\n",
        "        return self.check_entries(z_update)\n",
        "\n",
        "    def _z_update_T(self, l):\n",
        "        \"\"\"\n",
        "        Update z_{l,T} for l=1,...,L-1\n",
        "        z_{l,T} = q_{l,T}\n",
        "        \"\"\"\n",
        "        # Calculate helper vectors for final timestep\n",
        "        _, _, q_l, _ = self._calculate_p_s_q_r(l, self.T-1)\n",
        "\n",
        "        return self.check_entries(q_l)\n",
        "\n",
        "    def _z_update_L(self, t):\n",
        "        \"\"\"\n",
        "        Update z_{L,t} for the output layer (L) at intermediate timesteps t = 1,...,T-1\n",
        "        using the simplified formula:\n",
        "        z_{L,t} = (s_{L,t} + δ * r_{L,t+1}) / (1 + δ²)\n",
        "\n",
        "        Parameters:\n",
        "        - t: current timestep\n",
        "\n",
        "        Returns:\n",
        "        - z_{L,t} update\n",
        "        \"\"\"\n",
        "\n",
        "        # Calculate s_{L,t} and r_{L,t+1} for the intermediate timestep\n",
        "        _, s_L_t, _, _ = self._calculate_p_s_q_r(self.L - 1, t)\n",
        "        _, _, _, r_L_t_plus_1 = self._calculate_p_s_q_r(self.L - 1, t + 1)\n",
        "\n",
        "        # Numerator and denominator for the z update\n",
        "        numerator = s_L_t + self.delta * r_L_t_plus_1\n",
        "        denominator = 1 + self.delta ** 2\n",
        "\n",
        "        # Calculate z_{L,t}\n",
        "        z_update = numerator / denominator\n",
        "\n",
        "        return self.check_entries(z_update)\n",
        "\n",
        "    def _z_update_L_T(self, y):\n",
        "        \"\"\"\n",
        "        Update z_{L,T} for the output layer (L) at the final timestep T\n",
        "        using the formula:\n",
        "        z_{L,T} = (α * s_{L,T} + α * δ * r_{L,T+1} + (y - λ / 2)) / (α + δ² * α + 1)\n",
        "\n",
        "        Parameters:\n",
        "        - y: target output at the final timestep\n",
        "\n",
        "        Returns:\n",
        "        - z_{L,T} update\n",
        "        \"\"\"\n",
        "\n",
        "        # Set alpha as a constant value\n",
        "        alpha = self.rho / 2\n",
        "\n",
        "        # Calculate s_{L,T} and r_{L,T+1}\n",
        "        _, s_L_T, _, _ = self._calculate_p_s_q_r(self.L - 1, self.T - 2)\n",
        "        _, _, _, r_L_T_plus_1 = self._calculate_p_s_q_r(self.L - 1, self.T-1)\n",
        "\n",
        "        # Numerator and denominator for the z update\n",
        "        numerator = alpha * s_L_T + alpha * self.delta * r_L_T_plus_1 + (y - self.lambda_lagrange / 2)\n",
        "        denominator = alpha + (self.delta ** 2) * alpha + 1\n",
        "\n",
        "        # Calculate z_{L,T}\n",
        "        z_update = numerator / denominator\n",
        "\n",
        "        return self.check_entries(z_update)\n",
        "\n",
        "\n",
        "    def check_entries(self, z):\n",
        "        \"\"\"\n",
        "        Adjust entries of z based on a simplified cost approximation in a vectorized way.\n",
        "\n",
        "        Parameters:\n",
        "        - z: Tensor representing z_{l,t}^{n,m}, shape [N_l, M]\n",
        "\n",
        "        Returns:\n",
        "        - Adjusted tensor z with entries modified according to the conditions.\n",
        "        \"\"\"\n",
        "        theta = self.theta\n",
        "        epsilon = self.epsilon if hasattr(self, 'epsilon') else 1e-2\n",
        "\n",
        "        # Condition 1: z > theta and abs difference <= current value\n",
        "        mask1 = (z > theta) & (torch.abs(z - theta) <= torch.abs(z))\n",
        "        z[mask1] = theta\n",
        "\n",
        "        # Condition 2: z <= theta and abs difference with theta + epsilon < current value\n",
        "        mask2 = (z <= theta) & (torch.abs(z - (theta + epsilon)) < torch.abs(z))\n",
        "        z[mask2] = theta + epsilon\n",
        "\n",
        "        return z\n",
        "    # ============ lagrange multiplier update ============\n",
        "\n",
        "    def _lambda_update(self):\n",
        "        \"\"\"\n",
        "        Update the Lagrange multiplier lambda according to the ADMM update rule.\n",
        "\n",
        "        Formula:\n",
        "        lambda^+ = lambda + rho * (z_{L,T} - delta * z_{L,T-1} - W_L * a_{L-1,T})\n",
        "\n",
        "        Returns:\n",
        "        - Updated lambda\n",
        "        \"\"\"\n",
        "        # Retrieve the necessary variables for the update\n",
        "        z_L_T = self.z[self.L - 1][self.T - 1]       # z_{L,T}, shape [64, 10]\n",
        "        z_L_T_minus_1 = self.z[self.L - 1][self.T - 2]  # z_{L,T-1}, shape [64, 10]\n",
        "        W_L = self.W[self.L - 1]                     # Weight matrix W_L, shape [10, size of a_{L-1,T}]\n",
        "        a_L_minus_1_T = self.a[self.L - 2][self.T - 1]  # a_{L-1,T}, shape [64, W_L.shape[1]]\n",
        "\n",
        "        # Calculate the expression inside the parentheses\n",
        "        term = z_L_T - self.delta * z_L_T_minus_1 - torch.matmul(a_L_minus_1_T, W_L.T)\n",
        "\n",
        "        # Update lambda\n",
        "        lambda_update = self.lambda_lagrange + self.rho * term\n",
        "\n",
        "        # Update and return the lambda variable\n",
        "        self.lambda_lagrange = lambda_update\n",
        "        return self.lambda_lagrange\n",
        "\n",
        "    def feed_forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Implement forward pass using SNNTorch LIF neurons.\n",
        "        Returns membrane potentials of final layer.\n",
        "\n",
        "        Parameters:\n",
        "        - inputs: [timesteps, batch_size, input_dim]\n",
        "        Returns:\n",
        "        - mem[-1]: Final layer membrane potentials [batch_size, n_outputs]\n",
        "        \"\"\"\n",
        "        # Initialize membrane potentials for each layer\n",
        "        mem = []\n",
        "        spikes = []  # Track spikes for debugging\n",
        "        for l in range(self.L):\n",
        "            if l == 0:\n",
        "                mem.append(torch.zeros(inputs.shape[1], self.hidden_dims[0], device=self.device))\n",
        "            elif l == self.L - 1:\n",
        "                mem.append(torch.zeros(inputs.shape[1], self.n_outputs, device=self.device))\n",
        "            else:\n",
        "                mem.append(torch.zeros(inputs.shape[1], self.hidden_dims[l], device=self.device))\n",
        "\n",
        "        # Create LIF neurons for each layer\n",
        "        neurons = []\n",
        "        for l in range(self.L):\n",
        "            if l < self.L - 1:\n",
        "                # Hidden layers: reset by subtraction\n",
        "                lif = snn.Leaky(\n",
        "                    beta=self.delta,\n",
        "                    threshold=self.theta,\n",
        "                    reset_mechanism=\"subtract\",\n",
        "                    learn_beta=False,\n",
        "                    learn_threshold=False\n",
        "                )\n",
        "            else:\n",
        "                # Output layer: no reset\n",
        "                lif = snn.Leaky(\n",
        "                    beta=self.delta,\n",
        "                    threshold=self.theta,\n",
        "                    reset_mechanism=\"none\",\n",
        "                    learn_beta=False,\n",
        "                    learn_threshold=False\n",
        "                )\n",
        "            neurons.append(lif)\n",
        "\n",
        "        # Process each timestep and track activations\n",
        "        for t in range(inputs.shape[0]):\n",
        "            x = inputs[t]  # Current input slice\n",
        "\n",
        "            for l in range(self.L):\n",
        "\n",
        "                # Apply weights and LIF neuron dynamics\n",
        "                x = x @ self.W[l].T  # Apply weights\n",
        "\n",
        "                spike, mem[l] = neurons[l](x, mem[l])  # Apply LIF neuron\n",
        "                spikes.append(spike)  # Track spikes\n",
        "\n",
        "\n",
        "                # Spikes become input to the next layer\n",
        "                x = spike\n",
        "\n",
        "        # Check if final layer membrane potentials seem reasonable\n",
        "        final_output = mem[-1]\n",
        "        print(f\"\\nFinal Layer Membrane Potentials - Mean: {final_output.mean():.4f}, Std: {final_output.std():.4f}\")\n",
        "        print(f\"Final Layer Potential Range - Min: {final_output.min().item():.4f}, Max: {final_output.max().item():.4f}\")\n",
        "\n",
        "        return final_output  # [batch_size, n_outputs]\n",
        "    def evaluate(self, inputs, targets):\n",
        "        \"\"\"\n",
        "        Evaluate model performance on N-MNIST dataset with detailed prediction information.\n",
        "\n",
        "        Parameters:\n",
        "        - inputs: [timesteps, batch_size, input_dim]\n",
        "        - targets: [batch_size, 10] (one-hot encoded)\n",
        "\n",
        "        Returns:\n",
        "        - loss: Cross-entropy loss\n",
        "        - predictions: Final layer output\n",
        "        \"\"\"\n",
        "        print(\"\\n=== N-MNIST Evaluation ===\")\n",
        "\n",
        "        # Get final layer activity\n",
        "        raw_predictions = self.feed_forward(inputs)  # [batch_size, n_outputs]\n",
        "        predictions = F.softmax(raw_predictions, dim=1)\n",
        "        print(\"\\nFinal Layer Activity:\")\n",
        "        print(f\"Shape: {predictions.shape}\")\n",
        "        print(f\"Activity Stats - Mean: {predictions.mean():.4f}, Std: {predictions.std():.4f}\")\n",
        "        print(f\"Activity Range - Min: {predictions.min():.4f}, Max: {predictions.max():.4f}\")\n",
        "\n",
        "        # Calculate predictions and true classes\n",
        "        pred_classes = predictions.argmax(dim=1)  # Predicted classes\n",
        "        true_classes = targets.argmax(dim=1)          # True classes (from one-hot labels)\n",
        "\n",
        "        # Initialize confusion matrix and metrics storage\n",
        "        confusion_matrix = torch.zeros(10, 10, dtype=torch.int32)\n",
        "        metrics_per_class = []\n",
        "\n",
        "        # Display predictions count for each real class with highlight format\n",
        "        print(\"\\nDetailed Predictions for Each Real Class:\")\n",
        "        for class_idx in range(10):\n",
        "            # Mask for current class\n",
        "            class_mask = (true_classes == class_idx)\n",
        "\n",
        "            # Predictions for current class\n",
        "            predicted_for_class = pred_classes[class_mask]\n",
        "\n",
        "            # Count predictions for each possible class (0 to 9), with brackets for the current class index\n",
        "            predictions_count = []\n",
        "            for i in range(10):\n",
        "                count = (predicted_for_class == i).sum().item()\n",
        "                if i == class_idx:\n",
        "                    predictions_count.append(f\"[{count}]\")  # Highlight correct predictions with brackets\n",
        "                else:\n",
        "                    predictions_count.append(str(count))\n",
        "\n",
        "            print(f\"Real Class {class_idx} -> Prediction Counts: ({', '.join(predictions_count)})\")\n",
        "\n",
        "            # Populate confusion matrix row for real class\n",
        "            confusion_matrix[class_idx] = torch.tensor([int(predictions_count[i].strip(\"[]\")) for i in range(10)])\n",
        "\n",
        "            # Calculate metrics for current class\n",
        "            TP = confusion_matrix[class_idx, class_idx].float()\n",
        "            FP = confusion_matrix[:, class_idx].sum().float() - TP\n",
        "            FN = confusion_matrix[class_idx, :].sum().float() - TP\n",
        "\n",
        "            precision = TP / (TP + FP) if TP + FP > 0 else torch.tensor(0.0)\n",
        "            recall = TP / (TP + FN) if TP + FN > 0 else torch.tensor(0.0)\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else torch.tensor(0.0)\n",
        "\n",
        "            metrics_per_class.append({'precision': precision, 'recall': recall, 'f1': f1})\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        macro_precision = torch.stack([m['precision'] for m in metrics_per_class]).mean()\n",
        "        macro_recall = torch.stack([m['recall'] for m in metrics_per_class]).mean()\n",
        "        macro_f1 = torch.stack([m['f1'] for m in metrics_per_class]).mean()\n",
        "        accuracy = (pred_classes == true_classes).float().mean()\n",
        "\n",
        "        print(\"\\nOverall Metrics:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Macro Precision: {macro_precision:.4f}\")\n",
        "        print(f\"Macro Recall: {macro_recall:.4f}\")\n",
        "        print(f\"Macro F1-Score: {macro_f1:.4f}\")\n",
        "\n",
        "        # Calculate cross-entropy loss\n",
        "        loss = self.loss_fn(predictions, true_classes)\n",
        "        print(f\"\\nLoss: {loss.item():.6f}\")\n",
        "\n",
        "        return loss, predictions\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, inputs, targets, warm=True):\n",
        "        \"\"\"\n",
        "        Update the optimization variables following Algorithm 2 from the paper.\n",
        "        Architecture:\n",
        "        - L = 4 (3 hidden + 1 output)\n",
        "        - Layer 0: 1156 -> 128\n",
        "        - Layer 1: 128 -> 64\n",
        "        - Layer 2: 64 -> 32\n",
        "        - Layer 3: 32 -> 10\n",
        "        \"\"\"\n",
        "      #  print(\"\\nStarting optimization updates...\")\n",
        "        self.a_minus_one = inputs  # Initialize a_minus_one with the current batch of inputs\n",
        "\n",
        "        # First update hidden layers (0 to 2)\n",
        "        for l in range(self.L - 1):  # Layers 0, 1, 2\n",
        "            self.W[l] = self._weight_update(l)\n",
        "\n",
        "            for t in range(self.T - 1):\n",
        "                if l < self.L - 2:\n",
        "                    self.a[l][t] = self._activation_update(l, t)\n",
        "                else:\n",
        "                    self.a[l][t] = self._activation_update_Lminus1(t)\n",
        "\n",
        "                self.z[l][t] = self._z_update(l, t)\n",
        "\n",
        "\n",
        "            if l < self.L - 2:\n",
        "                self.a[l][self.T - 1] = self._activation_update_T(l)\n",
        "            else:\n",
        "                self.a[l][self.T - 1] = self._activation_update_Lminus1_T()\n",
        "\n",
        "\n",
        "            self.z[l][self.T - 1] = self._z_update_T(l)\n",
        "\n",
        "        self.W[self.L - 1] = self._weight_update_L(y=targets)\n",
        "\n",
        "        for t in range(self.T - 1):\n",
        "            self.z[self.L - 1][t] = self._z_update_L(t)\n",
        "\n",
        "        self.z[self.L - 1][self.T - 1] = self._z_update_L_T(targets)\n",
        "\n",
        "        if not warm:\n",
        "            self._lambda_update()\n",
        "\n",
        "        # Evaluate current performance (optional for debugging)\n",
        "        loss, predictions = self.evaluate(inputs, targets)\n",
        "        return loss, predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import tonic\n",
        "import tonic.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tonic import DiskCachedDataset\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import functional as SF\n",
        "from snntorch import utils\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define transformations\n",
        "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
        "frame_transform = transforms.Compose([\n",
        "    transforms.Denoise(filter_time=10000),\n",
        "    transforms.ToFrame(sensor_size=sensor_size, time_window=1000)\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "trainset = tonic.datasets.NMNIST(save_to='./data', transform=frame_transform, train=True)\n",
        "testset = tonic.datasets.NMNIST(save_to='./data', transform=frame_transform, train=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CE8E8qJZEvPy",
        "outputId": "5322ff84-d84e-4c48-d55f-6cd3eada8ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174,
          "referenced_widgets": [
            "676da2c7badb46e886cdb664726f2bd1",
            "373883c1b357489d95cabcaa0b56fbd6",
            "517d5ee73b1e4181824d64338427cc26",
            "0848d174c8bf4279bb74d04bdd36b19d",
            "632b7a57e54047078e8ff39da33bc29d",
            "5a619d4b26d44d55be993fb235fa64bf",
            "714d8af279d64d0c81ddf3a7143dc175",
            "96a60f8cce004a6d80c0520a2e566044",
            "5ab6ff6e3ca74a8eb0d85e6846795e03",
            "7220ef8dab5640d98ad77d449d850705",
            "4b6e540570f6448eba23fc75ccdd8deb",
            "e0270f0433dd47faa7f08b7bf372b933",
            "cf296dbdabc349e6bf9478ff8c8ee60c",
            "c0371dd8f81f4d79832eef3c98ed7a22",
            "cdd54fd8ca37444da16484695e8f86f4",
            "48af29e08ef4477ca15c2135e7231f90",
            "33eee554698e442d9cf7756a7cb7eab6",
            "442e2a05ecc54a1eb97b56ae22dd7de5",
            "6c27db1a797644dcab2cac310d02c337",
            "75d78899265e47e2946687578e6d9c92",
            "9a2210baf46f40de818d6dad3ff9ba84",
            "61bf99e9712748bbad4859b934a21127"
          ]
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/1afc103f-8799-464a-a214-81bb9b1f9337 to ./data/NMNIST/train.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1011893601 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "676da2c7badb46e886cdb664726f2bd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/NMNIST/train.zip to ./data/NMNIST\n",
            "Downloading https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/a99d0fee-a95b-4231-ad22-988fdb0a2411 to ./data/NMNIST/test.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169674850 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0270f0433dd47faa7f08b7bf372b933"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/NMNIST/test.zip to ./data/NMNIST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import tonic\n",
        "import tonic.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from typing import Tuple, List, Dict\n",
        "\n",
        "def prepare_nmnist_data(inputs: torch.Tensor,\n",
        "                       labels: torch.Tensor,\n",
        "                       device: torch.device,\n",
        "                       n_timesteps: int = 300) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Prepare NMNIST data for ADMM-SNN training.\n",
        "\n",
        "    Args:\n",
        "        inputs (torch.Tensor): Input spike data [batch_size, timesteps, channels]\n",
        "        labels (torch.Tensor): Labels\n",
        "        device (torch.device): Device to move data to\n",
        "        n_timesteps (int): Number of timesteps to use\n",
        "    \"\"\"\n",
        "    batch_size = inputs.shape[0]\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Truncate to desired number of timesteps\n",
        "    inputs = inputs[:, :n_timesteps]\n",
        "\n",
        "    # Reshape to [timesteps, batch_size, input_dim]\n",
        "    inputs = inputs.reshape(batch_size, n_timesteps, -1).permute(1, 0, 2).float()\n",
        "\n",
        "    # Normalize inputs to [0, 1] range\n",
        "    inputs = inputs / inputs.max()\n",
        "\n",
        "    # One-hot encode labels\n",
        "    labels_onehot = torch.zeros(batch_size, 10, device=device)\n",
        "    labels_onehot.scatter_(1, labels.unsqueeze(1), 1)\n",
        "\n",
        "    return inputs, labels_onehot\n",
        "\n",
        "def train(model, trainloader, num_epochs):\n",
        "    \"\"\"\n",
        "    Train ADMM-SNN model\n",
        "    \"\"\"\n",
        "    # Warming phase\n",
        "    print(\"\\nWarming Phase:\")\n",
        "    warming_losses = []\n",
        "    for epoch in range(2):\n",
        "        print(f'Warming Epoch [{epoch+1}/5]')\n",
        "        epoch_losses = []\n",
        "        epoch_accuracies = []\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
        "            print(f'  Batch [{batch_idx+1}/{len(trainloader)}]')\n",
        "            # Prepare data\n",
        "            inputs, labels = prepare_nmnist_data(inputs, labels, device)\n",
        "\n",
        "            # Warming step\n",
        "            loss, predictions = model.fit(inputs, labels, True)\n",
        "            # Calculate accuracy\n",
        "            pred_classes = torch.argmax(predictions, dim=1)\n",
        "            true_classes = torch.argmax(labels, dim=1)\n",
        "            accuracy = (pred_classes == true_classes).float().mean().item()\n",
        "\n",
        "            epoch_losses.append(loss)\n",
        "            epoch_accuracies.append(accuracy)\n",
        "        # Epoch summary\n",
        "        avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
        "        avg_acc = sum(epoch_accuracies) / len(epoch_accuracies)\n",
        "        warming_losses.append(avg_loss)\n",
        "        print(f'  Epoch Summary - Loss: {avg_loss:.6f}, Accuracy: {avg_acc:.4f}')\n",
        "\n",
        "\n",
        "    # Main training\n",
        "    print(\"\\nMain Training Phase:\")\n",
        "    training_metrics = []\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "        epoch_losses = []\n",
        "        epoch_accuracies = []\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
        "            print(f'  Batch [{batch_idx+1}/{len(trainloader)}]')\n",
        "\n",
        "            # Prepare data\n",
        "            inputs, labels = prepare_nmnist_data(inputs, labels, device)\n",
        "\n",
        "            # Training step\n",
        "            loss, predictions = model.fit(inputs, labels,False)\n",
        "\n",
        "            # Ensure predictions and labels have correct shape\n",
        "            labels = labels.t()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            pred_classes = torch.argmax(predictions, dim=1)\n",
        "            true_classes = torch.argmax(labels, dim=1)\n",
        "            accuracy = (pred_classes == true_classes).float().mean().item()\n",
        "\n",
        "            epoch_losses.append(loss)\n",
        "            epoch_accuracies.append(accuracy)\n",
        "\n",
        "\n",
        "\n",
        "        # Epoch summary\n",
        "        avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
        "        avg_acc = sum(epoch_accuracies) / len(epoch_accuracies)\n",
        "        training_metrics.append({\n",
        "            'epoch': epoch + 1,\n",
        "            'loss': avg_loss,\n",
        "            'accuracy': avg_acc\n",
        "        })\n",
        "        print(f'  Epoch Summary - Loss: {avg_loss:.6f}, Accuracy: {avg_acc:.4f}')\n",
        "\n",
        "    return warming_losses, training_metrics\n",
        "\n",
        "def evaluate(model, testloader):\n",
        "    print(\"\\nEvaluation Phase:\")\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    num_batches = 0\n",
        "    batch_metrics = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, labels) in enumerate(testloader):\n",
        "            print(f'  Batch [{batch_idx+1}/{len(testloader)}]')\n",
        "\n",
        "            # Prepare data\n",
        "            inputs, labels = prepare_nmnist_data(inputs, labels, device)\n",
        "\n",
        "            # Forward pass\n",
        "            loss, predictions = model.evaluate(inputs, labels)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            pred_classes = torch.argmax(predictions, dim=0)\n",
        "            true_classes = torch.argmax(labels, dim=0)\n",
        "            accuracy = (pred_classes == true_classes).float().mean().item()\n",
        "\n",
        "            # Store batch metrics\n",
        "            batch_metrics.append({\n",
        "                'batch': batch_idx + 1,\n",
        "                'loss': loss,\n",
        "                'accuracy': accuracy\n",
        "            })\n",
        "\n",
        "            total_loss += loss\n",
        "            total_acc += accuracy\n",
        "            num_batches += 1\n",
        "\n",
        "            print(f'    Loss: {loss:.6f}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_acc = total_acc / num_batches\n",
        "\n",
        "    print(f'\\nFinal Evaluation Results:')\n",
        "    print(f'  Average Loss: {avg_loss:.6f}')\n",
        "    print(f'  Average Accuracy: {avg_acc:.4f}')\n",
        "\n",
        "    return avg_loss, avg_acc, batch_metrics"
      ],
      "metadata": {
        "id": "ZZTYxOQZEwKx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Initialize model and training\n",
        "n_timesteps = 300\n",
        "input_dim =   sensor_size[0] * sensor_size[1]\n",
        "hidden_dims = [256,256]\n",
        "n_outputs = 10\n",
        "# DataLoaders\n",
        "\n",
        "\n",
        "# Create DataLoaders with the subsets\n",
        "batch_size = 256\n",
        "# Calculate size of 20% of data\n",
        "train_size = int( len(trainset)) // batch_size * batch_size\n",
        "test_size = int(  len(testset)) // batch_size * batch_size\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "train_subset = Subset(trainset, torch.randperm(len(trainset))[:train_size])\n",
        "test_subset = Subset(testset, torch.randperm(len(testset))[:test_size])\n",
        "\n",
        "\n",
        "\n",
        "trainloader = DataLoader(train_subset,\n",
        "                        batch_size=batch_size,\n",
        "                        collate_fn=tonic.collation.PadTensors(),\n",
        "                        shuffle=True)\n",
        "testloader = DataLoader(test_subset,\n",
        "                       batch_size=batch_size,\n",
        "                       collate_fn=tonic.collation.PadTensors())\n",
        "\n",
        "print(f\"Original training set size: {len(trainset)}\")\n",
        "print(f\"training set size: {len(train_subset)}\")\n",
        "print(f\"Original test set size: {len(testset)}\")\n",
        "print(f\"test set size: {len(test_subset)}\")\n",
        "\n",
        "\n",
        "rho = 0.15\n",
        "delta = 0.5\n",
        "theta = 0.2\n",
        "\n",
        "\n",
        "# Create model\n",
        "print(\"\\nInitializing model...\")\n",
        "model = ADMM_SNN(\n",
        "    n_samples=batch_size,\n",
        "    n_timesteps=n_timesteps,\n",
        "    input_dim=input_dim,\n",
        "    hidden_dims=hidden_dims,  # Changed final dimension to 10\n",
        "    n_outputs=10,\n",
        "    rho=rho,\n",
        "    delta=delta,\n",
        "    theta=theta\n",
        ")\n",
        "print(model)\n",
        "\n",
        "\n",
        "# Train model\n",
        "print(\"\\nStarting training process...\")\n",
        "num_epochs = 20\n",
        "warming_losses, training_metrics = train(model, trainloader, num_epochs)\n",
        "\n",
        "# Evaluate model\n",
        "print(\"\\nEvaluating model...\")\n",
        "test_loss, test_acc, test_metrics = evaluate(model, testloader)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nTraining Summary:\")\n",
        "print(f\"  Warming phase final loss: {warming_losses[-1]:.6f}\")\n",
        "print(f\"  Training final loss: {training_metrics[-1]['loss']:.6f}\")\n",
        "print(f\"  Training final accuracy: {training_metrics[-1]['accuracy']:.4f}\")\n",
        "print(\"\\nTest Results:\")\n",
        "print(f\"  Test Loss: {test_loss:.6f}\")\n",
        "print(f\"  Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "5NuMotZ4FSLu",
        "outputId": "5811514d-5d19-402d-9147-d8d2bc8cb773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original training set size: 60000\n",
            "training set size: 59904\n",
            "Original test set size: 10000\n",
            "test set size: 9984\n",
            "\n",
            "Initializing model...\n",
            "\n",
            "Model Initialization Details:\n",
            "Device: cpu\n",
            "Previous activation shape: torch.Size([300, 256, 1156])\n",
            "Weight layer 0 shape: torch.Size([256, 1156])\n",
            "Weight layer 1 shape: torch.Size([256, 256])\n",
            "Weight layer 2 shape: torch.Size([10, 256])\n",
            "z[0] shape: torch.Size([300, 256, 256])\n",
            "z[1] shape: torch.Size([300, 256, 256])\n",
            "z[2] shape: torch.Size([300, 256, 10])\n",
            "a[0] shape: torch.Size([300, 256, 256])\n",
            "a[1] shape: torch.Size([300, 256, 256])\n",
            "lambda shape: torch.Size([256, 10])\n",
            "ADMM SNN Model Structure:\n",
            " - rho: 0.15, delta: 0.5, theta: 0.2\n",
            " - Number of timesteps: 300\n",
            " - Input dimension: torch.Size([300, 256, 1156])\n",
            " - Hidden layers: [torch.Size([256, 1156]), torch.Size([256, 256]), torch.Size([10, 256])]\n",
            " - Output dimension (Lagrange Multiplier): torch.Size([256, 10])\n",
            " - self.L : 3\n",
            " - self.T : 300\n",
            "\n",
            "\n",
            "Starting training process...\n",
            "\n",
            "Warming Phase:\n",
            "Warming Epoch [1/5]\n",
            "  Batch [1/234]\n",
            "\n",
            "=== N-MNIST Evaluation ===\n",
            "\n",
            "Final Layer Membrane Potentials - Mean: 0.0238, Std: 0.0569\n",
            "Final Layer Potential Range - Min: -0.0060, Max: 0.3466\n",
            "\n",
            "Final Layer Activity:\n",
            "Shape: torch.Size([256, 10])\n",
            "Activity Stats - Mean: 0.1000, Std: 0.0004\n",
            "Activity Range - Min: 0.0950, Max: 0.1038\n",
            "\n",
            "Detailed Predictions for Each Real Class:\n",
            "Real Class 0 -> Prediction Counts: ([2], 2, 2, 1, 2, 0, 8, 0, 2, 1)\n",
            "Real Class 1 -> Prediction Counts: (1, [5], 2, 1, 2, 2, 8, 1, 3, 2)\n",
            "Real Class 2 -> Prediction Counts: (2, 3, [2], 3, 1, 3, 10, 2, 4, 1)\n",
            "Real Class 3 -> Prediction Counts: (3, 3, 1, [4], 0, 1, 7, 0, 2, 2)\n",
            "Real Class 4 -> Prediction Counts: (5, 2, 0, 1, [6], 2, 13, 1, 3, 3)\n",
            "Real Class 5 -> Prediction Counts: (2, 3, 0, 4, 1, [3], 4, 0, 4, 0)\n",
            "Real Class 6 -> Prediction Counts: (3, 4, 2, 4, 0, 1, [11], 1, 5, 2)\n",
            "Real Class 7 -> Prediction Counts: (5, 3, 0, 2, 1, 1, 7, [0], 2, 2)\n",
            "Real Class 8 -> Prediction Counts: (3, 8, 0, 0, 1, 1, 3, 0, [2], 2)\n",
            "Real Class 9 -> Prediction Counts: (0, 3, 0, 1, 5, 4, 6, 0, 1, [2])\n",
            "\n",
            "Overall Metrics:\n",
            "Accuracy: 0.1445\n",
            "Macro Precision: 0.3682\n",
            "Macro Recall: 0.1357\n",
            "Macro F1-Score: 0.1699\n",
            "\n",
            "Loss: 2.302560\n",
            "  Batch [2/234]\n",
            "\n",
            "=== N-MNIST Evaluation ===\n",
            "\n",
            "Final Layer Membrane Potentials - Mean: 0.0004, Std: 0.0063\n",
            "Final Layer Potential Range - Min: -0.0450, Max: 0.0561\n",
            "\n",
            "Final Layer Activity:\n",
            "Shape: torch.Size([256, 10])\n",
            "Activity Stats - Mean: 0.1000, Std: 0.0000\n",
            "Activity Range - Min: 0.0999, Max: 0.1001\n",
            "\n",
            "Detailed Predictions for Each Real Class:\n",
            "Real Class 0 -> Prediction Counts: ([3], 2, 3, 0, 13, 1, 1, 0, 0, 0)\n",
            "Real Class 1 -> Prediction Counts: (14, [2], 1, 0, 11, 1, 1, 0, 0, 0)\n",
            "Real Class 2 -> Prediction Counts: (9, 2, [2], 1, 10, 0, 2, 1, 0, 0)\n",
            "Real Class 3 -> Prediction Counts: (9, 6, 1, [1], 11, 0, 3, 1, 0, 0)\n",
            "Real Class 4 -> Prediction Counts: (6, 1, 1, 0, [17], 0, 1, 1, 0, 1)\n",
            "Real Class 5 -> Prediction Counts: (9, 0, 1, 0, 7, [0], 0, 0, 0, 0)\n",
            "Real Class 6 -> Prediction Counts: (9, 0, 1, 0, 11, 0, [1], 0, 0, 0)\n",
            "Real Class 7 -> Prediction Counts: (10, 5, 1, 0, 11, 0, 2, [1], 0, 0)\n",
            "Real Class 8 -> Prediction Counts: (2, 2, 0, 0, 14, 0, 2, 0, [1], 0)\n",
            "Real Class 9 -> Prediction Counts: (5, 2, 2, 0, 17, 0, 0, 0, 0, [0])\n",
            "\n",
            "Overall Metrics:\n",
            "Accuracy: 0.1094\n",
            "Macro Precision: 0.3969\n",
            "Macro Recall: 0.1036\n",
            "Macro F1-Score: 0.1120\n",
            "\n",
            "Loss: 2.302586\n",
            "  Batch [3/234]\n",
            "\n",
            "=== N-MNIST Evaluation ===\n",
            "\n",
            "Final Layer Membrane Potentials - Mean: 0.0001, Std: 0.0006\n",
            "Final Layer Potential Range - Min: -0.0001, Max: 0.0054\n",
            "\n",
            "Final Layer Activity:\n",
            "Shape: torch.Size([256, 10])\n",
            "Activity Stats - Mean: 0.1000, Std: 0.0000\n",
            "Activity Range - Min: 0.1000, Max: 0.1000\n",
            "\n",
            "Detailed Predictions for Each Real Class:\n",
            "Real Class 0 -> Prediction Counts: ([9], 4, 4, 2, 2, 0, 1, 1, 1, 2)\n",
            "Real Class 1 -> Prediction Counts: (13, [2], 1, 0, 1, 0, 0, 1, 0, 2)\n",
            "Real Class 2 -> Prediction Counts: (10, 0, [2], 1, 1, 0, 0, 3, 0, 1)\n",
            "Real Class 3 -> Prediction Counts: (15, 1, 0, [3], 3, 1, 0, 2, 0, 3)\n",
            "Real Class 4 -> Prediction Counts: (17, 5, 5, 3, [2], 1, 1, 0, 1, 0)\n",
            "Real Class 5 -> Prediction Counts: (14, 0, 0, 1, 0, [0], 0, 0, 0, 1)\n",
            "Real Class 6 -> Prediction Counts: (10, 3, 3, 3, 1, 1, [1], 1, 0, 1)\n",
            "Real Class 7 -> Prediction Counts: (19, 1, 4, 0, 0, 3, 0, [2], 0, 4)\n",
            "Real Class 8 -> Prediction Counts: (14, 7, 2, 1, 1, 0, 0, 1, [0], 2)\n",
            "Real Class 9 -> Prediction Counts: (19, 2, 1, 0, 1, 1, 1, 0, 0, [3])\n",
            "\n",
            "Overall Metrics:\n",
            "Accuracy: 0.0938\n",
            "Macro Precision: 0.3032\n",
            "Macro Recall: 0.0931\n",
            "Macro F1-Score: 0.1390\n",
            "\n",
            "Loss: 2.302585\n",
            "  Batch [4/234]\n",
            "\n",
            "=== N-MNIST Evaluation ===\n",
            "\n",
            "Final Layer Membrane Potentials - Mean: 0.0002, Std: 0.0010\n",
            "Final Layer Potential Range - Min: -0.0000, Max: 0.0092\n",
            "\n",
            "Final Layer Activity:\n",
            "Shape: torch.Size([256, 10])\n",
            "Activity Stats - Mean: 0.1000, Std: 0.0000\n",
            "Activity Range - Min: 0.1000, Max: 0.1000\n",
            "\n",
            "Detailed Predictions for Each Real Class:\n",
            "Real Class 0 -> Prediction Counts: ([13], 0, 0, 5, 12, 0, 0, 4, 0, 0)\n",
            "Real Class 1 -> Prediction Counts: (27, [0], 0, 2, 8, 0, 0, 0, 0, 0)\n",
            "Real Class 2 -> Prediction Counts: (15, 0, [0], 1, 7, 0, 0, 0, 0, 1)\n",
            "Real Class 3 -> Prediction Counts: (15, 0, 0, [0], 11, 0, 0, 1, 0, 0)\n",
            "Real Class 4 -> Prediction Counts: (8, 1, 0, 0, [3], 0, 0, 1, 0, 0)\n",
            "Real Class 5 -> Prediction Counts: (22, 0, 0, 2, 6, [0], 0, 0, 0, 0)\n",
            "Real Class 6 -> Prediction Counts: (15, 0, 0, 2, 5, 1, [0], 1, 0, 0)\n",
            "Real Class 7 -> Prediction Counts: (15, 0, 0, 1, 6, 0, 0, [0], 0, 0)\n",
            "Real Class 8 -> Prediction Counts: (11, 0, 0, 0, 10, 0, 0, 1, [0], 0)\n",
            "Real Class 9 -> Prediction Counts: (14, 0, 0, 2, 7, 0, 0, 0, 0, [0])\n",
            "\n",
            "Overall Metrics:\n",
            "Accuracy: 0.0625\n",
            "Macro Precision: 0.1073\n",
            "Macro Recall: 0.0613\n",
            "Macro F1-Score: 0.0664\n",
            "\n",
            "Loss: 2.302585\n",
            "  Batch [5/234]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-030c9b358c68>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStarting training process...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mwarming_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-a82b4945804f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, num_epochs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# Warming step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0;31m# Calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mpred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-86eeb8d2f68f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, targets, warm)\u001b[0m\n\u001b[1;32m    770\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activation_update_Lminus1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_z_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-86eeb8d2f68f>\u001b[0m in \u001b[0;36m_z_update\u001b[0;34m(self, l, t)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# Calculate helper vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_p_s_q_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;31m# Calculate initial z update (before check_entries)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-86eeb8d2f68f>\u001b[0m in \u001b[0;36m_calculate_p_s_q_r\u001b[0;34m(self, l, t)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;31m# Calculate p_l: project previous layer activations through weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mp_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_l_minus_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, features]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# Calculate s_l: add decayed previous z values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}